import os
import sys
import subprocess
import re
import numpy as np
import pandas as pd
import pysam
import anndata as ad

#################################### USER CONFIGURATION ####################################

# Path to config file
configfile: 'config/config.yaml'

# Create the output directory
outdir = config['outdir']
if not os.path.exists(outdir):
    os.makedirs(outdir)

# Path to barcode table
barcode_file = f"{outdir}/barcodes.tsv"

#################################### PREP BARCODES AND SAMPLETABLE ####################################

# NOTE: 
# - Manually prep data frames for metadata and sampletable
# - Ensure that the meta_df includes the three required columns
#   specified in config['key_col'], config['index_col'], and config['bam_col']

# Prep sampletable
sampletable = pd.read_csv(config['sampletable']).set_index(config['index_col'], drop=False)
sampletable[config['bam_col']] = config['bam_dir'] + "/" + sampletable.index + '_possorted_genome_bam.bam'

# Break if input bams don't align with sampletable
missing_bams = [b for b in sampletable[config['bam_col']] if not os.path.isfile(b)]
if len(missing_bams) > 0:
    raise ValueError(f"{missing_bams} not found in the directory!")

# Prep barcode table
meta_list = []
for celltype, path in config['adata'].items():
    # Read AnnData
    meta_df = ad.read_h5ad(path).obs[list(config['all_cols'])]
    # Add new columns for celltypes and barcodes
    meta_df['celltype'] = celltype
    meta_df['barcode'] = meta_df.index
    # Remove sample suffixes from the barcodes
    barcode_df = meta_df['barcode'].str.split('_', expand=True)
    barcode_df.columns = ['barcode', config['index_col']]
    # Add new columns to the metadata
    meta_df['barcode'] = barcode_df['barcode']
    meta_df[config['index_col']] = barcode_df[config['index_col']]
    meta_list.append(meta_df)

# Save all barcodes in a tsv file
meta_df = pd.concat(meta_list, axis=0)

# Add bam file paths to the metadata table and save as a tsv file
meta_df = pd.merge(sampletable.loc[:, [config['index_col'], config['key_col'], config['bam_col']]].reset_index(drop=True),
                   meta_df,
                   how="right",
                   on=[config['index_col'], config['key_col']])
meta_df.to_csv(barcode_file, sep="\t", index=False)

# Prep a dictionary with keys corresponding to groups 
# and values corresponding to unique sample ids
group_dic = {}
for g in list(set(meta_df[config['key_col']])):
    # Filter rows for group
    df = meta_df[meta_df[config['key_col']] == g]
    group_dic[g] = list(set(df[config['index_col']]))

#################################### PREP FUNCTIONS ####################################

# Function to extract SQ-header from a bam file
def extract_headers_SQ(bam):
    # Collect unique SQ header reads in a set
    headers = set()
    with pysam.AlignmentFile(bam, "rb") as f:
        for line in f.header['SQ']:
            headers.add((line['SN'], line['LN']))
    return headers

def list_group_sams(wildcards):
    groups = group_dic[wildcards.group]
    samlist = [f"{outdir}/sam/{g}_{wildcards.celltype}.sam" for g in groups]
    return samlist

#################################### RULES ####################################


rule all:
    input:
        expand("{outdir}/bam/group/{group}_{celltype}_sorted.bam.bai",
            outdir=config['outdir'],
            group=list(set(meta_df[config['key_col']])),
            celltype=list(set(meta_df[config['celltype_col']]))),
        expand("{outdir}/juncfiles.txt", outdir=config['outdir']),
        expand("{outdir}/bed/sample/{sample}_{celltype}_regtools.junc",
            outdir=config['outdir'],
            sample=list(set(meta_df[config['index_col']])),
            celltype=list(set(meta_df[config['celltype_col']])))


rule create_header:
    """
    This rule checks whether all headers (@SQ) are identical across the samples
    and creates header
    """
    input:
        bams = lambda wildcards: [b for b in set(meta_df['bam']) if pd.notnull(b) and os.path.isfile(b)]
    output:
        sam = "{outdir}/header.sam"
    resources:
        mem_mb = 1024 * 20,
        disk_mb = 1024 * 10,
        runtime = 30
    run:
        header_list = []
        for bam in input.bams:
            header_set = extract_headers_SQ(bam)
            if header_set not in header_list:
                header_list.append(header_set)
        if len(header_list) != 1:
            raise ValueError("Headers are discordant across the samples!")
        else:
            shell('samtools view -H {input.bams[0]} | grep "^@SQ" > {output.sam}')

rule prep_sam:
    """
    This rule preps barcodes corresonding to the celltype of interest in a txt file
    """
    input:
        header = "{outdir}/header.sam",
        bam = lambda wildcards: "{}/".format(config['bam_dir']) + "{sample}_possorted_genome_bam.bam"
    output:
        sam = "{outdir}/sam/{sample}_{celltype}.sam"
    resources:
        mem_mb = 1024 * 20,
        disk_mb = 1024 * 10,
        runtime = 720
    threads: 8
    params:
        genes = config['genes']
    run:
        # Sanity check for the input bam file
        if not os.path.exists(input.bam):
            raise ValueError("Input bam file not found!")
        # Filter rows by groups of interest
        df = meta_df[(meta_df[config['index_col']] == wildcards.sample)]
        if config['celltype_col'] != '':
            df = df[(df[config['celltype_col']] == wildcards.celltype)]
        # Create a list storing unique barcodes filtered by cluster and genotype
        barcode_list = [f"CB:Z:{barcode.strip()}" for barcode in set(df.barcode)]
        # Join barcodes into a single string (w header)
        barcode_joined = "|".join(barcode_list)
        # Prep a list for genes of interest
        gene_list = [f"GN:Z:{g.strip()}" for g in params.genes]
        # Join genes into a single string (w header)
        gene_joined = "|".join(gene_list)
        # Specify a temporary sam file 
        temp_sam = f"{wildcards.outdir}/{wildcards.sample}_{wildcards.celltype}_temp.sam"
        # Run samtools with or without module load samtools/1.19
        shell(
            """
            cat {input.header} > {output.sam}
            samtools view -@ {threads} {input.bam} | grep -E "{barcode_joined}" > {temp_sam} || true
            cat {temp_sam} | grep -E "{gene_joined}" >> {output.sam} || true
            rm -f {temp_sam}
            """
            )

rule create_sample_celltype_bam:
    """
    This rule aggregates header and filtered sam files into a bam file
    """
    input:
        sam = "{outdir}/sam/{sample}_{celltype}.sam"
    output:
        bam = "{outdir}/bam/sample/{sample}_{celltype}_sorted.bam",
        bai = "{outdir}/bam/sample/{sample}_{celltype}_sorted.bam.bai",
    resources:
        mem_mb = 1024 * 20,
        disk_mb = 1024 * 10,
        runtime = 60
    params:
        temp_bam = lambda wildcards: f"{wildcards.outdir}/bam/sample/{wildcards.sample}_{wildcards.celltype}_unsorted.bam"
    threads: 8
    shell:
        """
        cat {input.sam} | samtools view -bS -@ {threads} > {params.temp_bam}
        samtools sort -@ {threads} {params.temp_bam} -o {output.bam}
        samtools index {output.bam}
        rm {params.temp_bam}
        """

rule create_group_celltype_bam:
    """
    This rule aggregates header and filtered sam files into a bam file
    """
    input:
        sam = list_group_sams
    output:
        bam = "{outdir}/bam/group/{group}_{celltype}_sorted.bam",
        bai = "{outdir}/bam/group/{group}_{celltype}_sorted.bam.bai"
    params:
        temp_bam = lambda wildcards: f"{wildcards.outdir}/bam/group/{wildcards.group}_{wildcards.celltype}_unsorted.bam"
    resources:
        mem_mb = 1024 * 20,
        disk_mb = 1024 * 10,
        runtime = 60
    threads: 8
    shell:
        """
        samtools merge -f -@ {threads} {params.temp_bam} {input.sam}
        samtools sort -@ {threads} {params.temp_bam} -o {output.bam}
        samtools index {output.bam}
        rm {params.temp_bam}
        """

rule extract_junctions:
    """
    This rule captures splicing junctions using regtools extract.
    If a bam input file contains no reads, this rule will return
    an ampty bed file. 
    Note that the output bed file name has to end with `.junc`.
    """
    input:
        bam = "{outdir}/bam/sample/{sample}_{celltype}_sorted.bam",
        fasta = config['fasta']
    output:
        junc = "{outdir}/bed/sample/{sample}_{celltype}_regtools.junc"
    resources:
        mem_mb = 1024 * 20,
        disk_mb = 1024 * 10,
        runtime = 30
    threads: 8
    shell:
        """
        if ! regtools junctions extract -s XS -a 6 -m 30 -M 500000 -o {output.junc} {input.bam} {input.fasta}; then
            touch {output.junc}
        fi
        """

rule prep_juncfiles:
    """
    This rule prepares a text file storing all input junction 
    files (<sample>.junc) saved as a bed format. The output of this rule
    is required to count the number of junctions using leafcutter.
    """
    input:
        expand("{outdir}/bed/sample/{sample}_{celltype}_regtools.junc",
            outdir=config['outdir'],
            sample=list(set(meta_df[config['index_col']])),
            celltype=list(set(meta_df[config['celltype_col']])))
    output:
        "{outdir}/juncfiles.txt"
    resources:
        mem_mb = 1024 * 20,
        disk_mb = 1024 * 10,
        runtime = 10
    shell:
        """
        printf '%s\n' {input} > {output}
        """


