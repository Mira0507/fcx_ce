---
title: "Differential splicing analysis using MAST"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        toc: true
        toc_float: true
        toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to conduct differential splicing (DS) analysis
using [MAST](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-015-0844-5).

Refer to the following resources for technical details:

- [Documentation](https://rglab.github.io/MAST/index.html)
- [GitHub](https://github.com/RGLab/MAST/)

```{r libraries}
# Libraries
library(parallel)
library(tidyverse)
library(ggplot2)
library(reticulate)
library(parallel)
library(yaml)
library(reshape2)
library(limma)
library(NMF)
library(MAST)
library(RColorBrewer)
library(scater)
library(plotly)

# Additional options
set.seed(2570)
source('../config/helpers.R')
use_condaenv("../../../menv")

# Specify the number of available cores
n_cores <- future::availableCores()
options(mc.cores=n_cores)
```

```{r config}

# --------------------------------------------------------------------------------
# This chunk specifies input paths and variables in R
# --------------------------------------------------------------------------------

# Path to input matrix
mtx_path <- "../results/junction_counts/thalamus_sc_perind_numers.counts.gz"

# Path to metadata table
meta_path <- "../results/barcodes.tsv"

# Path to Snakemake config
snakemake_config <- "../config/config.yaml"

# Paths to AnnData
adata_paths <- read_yaml(snakemake_config)[['adata']] %>%
    map(~paste0("../", .x))

# Path to output directory
out_dir <- "ds"

# Create directories if missing
for (p in c(out_dir)) {
    if (! dir.exists(p)) { dir.create(p, recursive=TRUE) }
}

# Specify metadata columns for factors and factor levels
factor_groups <- list(
    general_disease=c('Control', 'FTD', 'AD'),
    cell_type=c('ExNeu1', 'ExNeu2'),
    study=c('Marsan', 'Biogen', 'Mathys'),
    study_specific_disease_specific=c('Control-Marsan',
                                      'Control-Biogen',
                                      'Control-Mathys',
                                      'FTD-Marsan',
                                      'FTD-Biogen',
                                      'AD-Mathys'),
    study_disease_specific_celltype=c('Control-Marsan_ExNeu1',
                                      'Control-Marsan_ExNeu2',
                                      'Control-Biogen_ExNeu1',
                                      'Control-Biogen_ExNeu2',
                                      'Control-Mathys_ExNeu1',
                                      'Control-Mathys_ExNeu2',
                                      'FTD-Marsan_ExNeu1',
                                      'FTD-Marsan_ExNeu2',
                                      'FTD-Biogen_ExNeu1',
                                      'FTD-Biogen_ExNeu2',
                                      'AD-Mathys_ExNeu1',
                                      'AD-Mathys_ExNeu2')
)

# Specify a column to subset barcodes
# NOTE: Set to NULL if unnecessary
subset_col <- list(study_celltype=c('study', 'cell_type'))

```

```{python ppackages}
import anndata as ad
import scanpy as sc
import pandas as pd
import numpy as np
import subprocess
import os
```


# Loading input data {.tabset}

The number of splicing junctions was counted based on cellranger-aligned reads mapped to the following
genes:

```{r genes_tested}
print(read_yaml(snakemake_config)[['genes']])
```

These counts were compiled into a junction-by-barcode matrix for differential testing.


```{python import_adata}

# --------------------------------------------------------------------------------
# This chunk imports input data and add the junction matrix to AnnData
# --------------------------------------------------------------------------------

# reticulate::repl_python()

# Import AnnData objects
adata_dic = {celltype: ad.read_h5ad(path) for celltype, path in r.adata_paths.items()}
adata_filtered = {}

# Import junction matrix
counts = pd.read_csv(r.mtx_path, sep=" ")

# Prep a function calculating junction length in Kb
def size_kb(coord):
    # Split the input coordinate. Assume the following format: 
    # "chr8:79611214:79616822:clu_1_+"
    parts = coord.split(":")
    start = int(parts[1])
    end = int(parts[2])
    # Calculate between the start and end sites in Kb
    distance = abs(end - start) / 1000
    return distance

for celltype in adata_dic.keys():
    # Retrieve an AnnData corresponding to the celltype
    ann = adata_dic[celltype]
    # Extract metadata
    obs = ann.obs
    # Add new columns required to subset barcodes if necessary
    if r.subset_col is not None:
        for key, value in r.subset_col.items():
            obs[key] = obs[value].astype(str).agg("_".join, axis=1)
    # Replace the input metadata with updated one
    ann.obs = obs
    # Update the input AnnData
    adata_dic[celltype] = ann
    # Extract cell barcodes
    target_cells = list(ann.obs.index)
    # Slice the junction count matrix based on the extracted barcodes that expresses
    # any of the junctions
    counts_subset = counts[target_cells]
    nonzero_cells = counts_subset.sum(axis=0) > 0
    counts_subset = counts_subset.loc[:, nonzero_cells]
    # Subset metadata
    obs_subset = obs.loc[counts_subset.columns, :]

    # Create a new AnnData obj
    ann_new = ad.AnnData(X=counts_subset.T, obs=obs_subset)
    ann_new.layers['counts'] = ann_new.X
    # Add log2-transformed values to the AnnData
    ann_new.layers['counts'] = ann_new.X
    ann_new.layers['log2'] = np.log2(ann_new.X + 1)

    # Calculate TPM
    # 1. Divide the read counts by the length of each gene in kilobases. This gives you reads 
    # per kilobase (RPK).
    # 2. Count up all the RPK values in a sample and divide this number by 1,000,000. This is 
    # your “per million” scaling factor.
    # 3. Divide the RPK values by the “per million” scaling factor. This gives you TPM.

    # Calculate the size of junctions
    length_list = [size_kb(c) for c in counts_subset.index]
    # Divide the raw counts by junction size, returning RPK
    counts_rpk = counts_subset.div(length_list, axis=0)
    # Calculate barcode-wise per million scaling factor
    per_barcode_million = counts_rpk.sum(axis=0) / 1_000_000
    # Convert into log2TPM scale with a pseudocount of 1
    tpm = counts_rpk.div(per_barcode_million, axis=1)
    log2tpm = np.log2(tpm + 1)
    # Replace missing values (NaN) with 1
    log2tpm = log2tpm.fillna(0)
    # Add log2TPM-transformed values to the AnnData
    ann_new.layers['log2TPM'] = log2tpm.T

    # Specify the path to updated AnnData
    updated_path = f"{r.out_dir}/{celltype}_JUNCTIONS.h5ad"
    # Save updated AnnData
    ann_new.write_h5ad(updated_path)

    # Replace the input AnnData with updated obj
    adata_filtered[celltype] = ann_new


```

Input AnnData objects for each celltype:

```{r infile_info}

for (name in names(adata_paths)) {
    print(paste0(name, ": ", adata_paths[[name]]))
}

```

Refer to the following data added to the `AnnData` objects:

- `AnnData.layers["counts"]`: raw junction counts
- `AnnData.layers["log2"]`: log2-transformed raw junction counts with a pseudocount of 1
- `AnnData.layers["log2TPM"]`: log2-transformed transcripts per million (TPM) 
  with a pseudocount of 1

Created `AnnData` objects are saved as:

```{r outfile_info}

for (name in names(adata_paths)) {
    print(paste0(name, ": ", out_dir, "/", name, "_JUNCTIONS.h5ad"))
}

```

The following table shows the number of barcodes for each study- and celltype-specific subset.
The `N_barcodes` column represents the number of barcodes that were initially loaded.

```{r n_barcodes, results='asis'}
# Print the number of barcodes for each obj
n_df <- lapply(py$adata_dic, function(o) {
    df <- as.data.frame(o$obs)
    n_list <- split(df, df[[names(subset_col)[1]]]) %>%
        lapply(nrow)
    data.frame(subset=names(n_list), N_barcodes=unlist(n_list)) }) %>%
    bind_rows() %>%
    remove_rownames()

knitr::kable(n_df)
```

```{r prep_sca}

# --------------------------------------------------------------------------------
# This chunk builds an SCA obj. Refer to the following instructions:
# - https://rglab.github.io/MAST/reference/FromMatrix.html
# - https://rglab.github.io/MAST/articles/MAST-interoperability.html
# This chunk requires manual intervention to some extent.
# --------------------------------------------------------------------------------

# Extract metadata for all input cells
adata_meta <- map(py$adata_filtered,
                  ~.x[['obs']] %>% rownames_to_column('barcode')) %>%
    bind_rows() %>%
    mutate(study_disease_specific_celltype=paste0(study_specific_disease_specific,
                                                  "_",
                                                  cell_type))

rownames(adata_meta) <- adata_meta[['barcode']]

# Refactor columns of interest
for (name in names(factor_groups)) {
    adata_meta[[name]] <- factor(adata_meta[[name]],
                                 levels=factor_groups[[name]])
}

# Split the metadata by study and celltype
adata_meta_list <- split(adata_meta, adata_meta[[names(subset_col)[1]]])

# Prep feature table
feature_meta <- data.frame(junction=rownames(py$counts))

# Extract log2TPM-transformed counts from AnnData objects
l2t_mat <- lapply(py$adata_filtered, function(o) {
    # Extract and clean the log2TPM count matrix
    mat <- o$layers[['log2TPM']] %>%
        as.data.frame()
    rownames(mat) <- rownames(o$obs)
    colnames(mat) <- o$var %>% rownames()
    return(mat) }) %>%
    bind_rows() %>%
    t()

# Build an sca obj using log2TPM-transformed counts
sca <- FromMatrix(l2t_mat,
                  cData=adata_meta,
                  fData=feature_meta,
                  check_sanity=FALSE)

# Add raw counts to the sca obj
assays(sca)$counts <- py$counts[, colnames(l2t_mat)]

# Create a list storing objects for subsets
sca_list <- list(all=sca)
for (subset in n_df[['subset']]) {
    barcode_x <- adata_meta[adata_meta[[names(subset_col)[1]]] == subset,] %>%
        rownames()
    sca_x <- sca[, barcode_x]
    sca_list[[subset]] <- sca_x
}



# How to access to raw or transformed counts
# - Transformed counts: `assay(sca)` or `assays(sca)$et`
# - Raw counts: `assays(sca)$counts`
```

Input matrices are prepared as *raw* (e.g. `assays(SCA)$counts`) 
and *log2-transformed TPM values (with a pseudocount of 1)* (e.g. `assays(SCA)$et`)
in the `SingleCellAssay(SCA)` object. 

# Quality Control (QC)

## Pre-filtering barcodes

Cells are removed if none of the junctions are detected. The number of remaining barcodes after filtering
is shown in the `N_remaining` column. The percentage of remaining cells relative to input
(`N_remaining / N_barcodes x 100`) is shown in the `percentage` column.

```{r prefiltering, results='asis'}

# --------------------------------------------------------------------------------
# This chunk displays the number of barcodes before and after filtering zero-count
# cells
# --------------------------------------------------------------------------------

data.frame(subset=names(sca_list), N_remaining=sapply(sca_list, ncol)) %>%
    right_join(n_df, by="subset") %>%
    mutate(percentage=N_remaining/N_barcodes * 100,
           percentage=round(percentage, 2)) %>%
    knitr::kable()
```

## Heatmap {.tabset}

Cell-to-cell similarity is explored using a heatmap generated from non-zero cells, with *Euclidean distance* 
represented by the color scale. Darker blue indicates less distance (i.e., greater similarity)
in splice junction profiling.

```{r qc_heatmap, results='asis', fig.height=12, fig.width=12, cache=TRUE}

# --------------------------------------------------------------------------------
# This chunk creates cell-to-cell similarity heatmap
# --------------------------------------------------------------------------------

for (name in names(sca_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Retrieve obj
    o <- sca_list[[name]]
    # Retrieve log2TPM matrix
    sampleDistsMatrix <- as.matrix(dist(t(assay(o))))

    # Set color to be displayed
    colors <- colorRampPalette(rev(RColorBrewer::brewer.pal(9, 'Blues')))(255)

    # Prep metadata for heatmap
    heatmap_meta <- as.data.frame(colData(o)[, names(factor_groups)])

    # Print heatmap
    print(pheatmap::pheatmap(
        sampleDistsMatrix,
        scale='none',
        color=colors,
        annotation_col=heatmap_meta,
        show_rownames=FALSE,
        show_colnames=FALSE,
        cluster_cols=TRUE,
        border_color=NA
    )
    )
    cat('\n\n')
}
```

## Dimensionality reduction {.tabset}

Junction profiling is explored across cells in reduced dimensions such as PCA and UMAP. Each dot 
represents a single cell, along with color codes corresponding to different conditions.

```{r prep_umap}

# --------------------------------------------------------------------------------
# This chunk prepares log2TPM count matrices and metadata for each subset
# --------------------------------------------------------------------------------

count_list <- lapply(sca_list,
                     function(o) list(mat=as.data.frame(assay(o)),
                                      meta=as.data.frame(colData(o))))
```

```{python dimred}

# --------------------------------------------------------------------------------
# This chunk runs dimensionality reduction
# --------------------------------------------------------------------------------

umap_dic = {}
pca_dic = {}

for subset in r.count_list.keys():
    # Retrieve input for AnnData
    obj_x = r.count_list[subset]
    mat_x = obj_x['mat']
    meta_x = obj_x['meta']

    # Create an AnnData obj
    adata_x = ad.AnnData(X=mat_x.T, obs=meta_x)

    # Run PCA
    sc.tl.pca(adata_x)

    # Find neighbors
    sc.pp.neighbors(adata_x)

    # Run UMAP
    sc.tl.umap(adata_x)

    # Retrieve PCA and UMAP coordinates (2D)
    umap_dic[subset] = adata_x.obsm['X_umap']
    pca_dic[subset] = adata_x.obsm['X_pca']
```

```{r present_dimred, results='asis', fig.height=6, fig.width=6}

# --------------------------------------------------------------------------------
# This chunk plots UMAP
# --------------------------------------------------------------------------------
stop()
# Consolidate metadata and coordinates in reduced dimensions across the subsets
coord_list <- map2(py$pca_dic,
                   py$umap_dic,
                   ~cbind(.x[, 1:2], .y[, 1:2]) %>%
                       as.data.frame %>%
                       set_names(c('PC1', 'PC2', 'UMAP1', 'UMAP2'))) %>%
    map2(count_list, ~cbind(.y[['meta']], .x))

for (subset in names(coord_list)) {
    cat('###', subset, '{.tabset}\n\n')
    for (name in names(factor_groups)) {
        cat('####', name, '{.tabset}\n\n')
        for (dimred in c('PCA', 'UMAP')) {
            cat('#####', dimred, '\n\n')
            # Specify column names for the X and Y axes
            axes <- ifelse(dimred == "PCA", "PC", "UMAP") %>%
                paste0(1:2)
            # Prep input data frame for plotting
            df <- coord_list[[subset]][, c(name, axes, "barcode")]
            # Plot
            p <- ggplot(df, aes_string(x=axes[1], y=axes[2], color=name)) +
                geom_point(alpha=0.7) +
                theme_bw()
            print(p)
            cat('\n\n')
        }
    }
}
```

## Count distribution {.tabset}

The number of splice junction counts are inspected across the samples and conditions of interest.
Each tab displays raw (`raw`) or log2TPM (`norm`) junction counts on the y-axis.

```{r count_distribution, results='asis'}

# --------------------------------------------------------------------------------
# This chunk plots the distribution of raw and normalized counts
# --------------------------------------------------------------------------------

for (subset in names(sca_list)) {
    cat('###', subset, '{.tabset}\n\n')
    # Retrieve SCA obj
    o <- sca_list[[subset]]
    # Extract metadata from the obj
    o_meta <- colData(o)[, names(factor_groups)] %>%
        as.data.frame %>%
        rownames_to_column('barcode')
    # Extract raw and normalized counts from the obj and clean data frame for plotting
    mat_list <- list(raw=assays(o)$counts, norm=assays(o)$et) %>%
        lapply(function(df) df %>%
               as.data.frame %>%
               rownames_to_column('junction') %>%
               gather('barcode', 'counts', -junction) %>%
               left_join(o_meta, by='barcode'))

    # Create boxplots
    for (counttype in names(mat_list)) {
        plot_df <- mat_list[[counttype]]
        cat('####', counttype, '{.tabset}\n\n')
        for (condition in names(factor_groups)) {
            cat('#####', condition, '\n\n')
            p <- ggplot(plot_df,
                        aes_string(x=condition, y='counts', fill=condition)) +
                theme_bw() +
                geom_boxplot(color='black', width=0.5) +
                ylab("Splice Junction Counts") +
                theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),
                      axis.title.x=element_blank())
            p <- if (counttype == "raw") {
                p + scale_y_log10()
            }
            print(p)
            cat('\n\n')
        }
    }
}


```

# Differential testing 

```{r calculate_cdr, eval=FALSE}

for (subset in names(sca_list)) {
    o <- sca_list[[subset]]
    # Add cellular detection rate (CDR) to metadata
    cdr <- colSums(assay(o) > 0)
    colData(o)$cngeneson <- scale(cdr)
    sca_list[[subset]] <- o
}

```


# Session info

```{r session_info, collapse=FALSE}
sessionInfo()
```



