---
title: "Pseudobulk differential analysis on cryptic exons (CEs)"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        toc: true
        toc_float: true
        toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to conduct pseudobulk differential analysis
using [Fisher's exact test](https://en.wikipedia.org/wiki/Fisher%27s_exact_test). This method
tests *differential detection* of each splice junction.


```{r libraries}
# Libraries
library(tidyverse)
library(DESeq2)
library(ggplot2)
library(parallel)
library(yaml)
library(RColorBrewer)
library(plotly)
library(parallel)
library(rtracklayer)
library(GenomicRanges)
library(GenomicFeatures)

# Additional options
set.seed(2570)
source('../config/helpers.R')

# Specify the number of available cores
n_cores <- future::availableCores()
options(mc.cores=n_cores)
```

```{r config}

# --------------------------------------------------------------------------------
# This chunk specifies input paths and variables in R
# --------------------------------------------------------------------------------

# Path to input matrices
in_rds <- "sc-exploratory/aggr_matrices.rds"

# Path to Snakemake config
snakemake_config <- "../config/config.yaml"

# Paths to yaml config
config_yaml <- read_yaml(snakemake_config)

# Path to output directory
out_dir <- "sc-fisherexact"

# Path to GTF
gtf_path <- "../../../input/thalamus_excitatory/genes.gtf.gz"

# Create directories if missing
for (p in c(out_dir)) {
    if (! dir.exists(p)) { dir.create(p, recursive=TRUE) }
}

# Specify a pseudocount to be added to count matrices
# NOTE: The sparsity of single cell matrix sometimes causes an error
#       that cannot calculate geometric means because of many zeros. 
#       This issue is prevented by adding a small pseudocount.
pseudocount <- 1

# Specify metadata columns for factors and factor levels
factor_groups <- list(
    general_disease=c('Control', 'FTD', 'AD'),
    cell_type=c('ExNeu1', 'ExNeu2'),
    study=c('Marsan', 'Biogen', 'Mathys'),
    study_specific_disease_specific=c('Control-Marsan',
                                      'Control-Biogen',
                                      'Control-Mathys',
                                      'FTD-Marsan',
                                      'FTD-Biogen',
                                      'AD-Mathys'),
    study_disease_specific_celltype=c('Control-Marsan_ExNeu1',
                                      'Control-Marsan_ExNeu2',
                                      'Control-Biogen_ExNeu1',
                                      'Control-Biogen_ExNeu2',
                                      'Control-Mathys_ExNeu1',
                                      'Control-Mathys_ExNeu2',
                                      'FTD-Marsan_ExNeu1',
                                      'FTD-Marsan_ExNeu2',
                                      'FTD-Biogen_ExNeu1',
                                      'FTD-Biogen_ExNeu2',
                                      'AD-Mathys_ExNeu1',
                                      'AD-Mathys_ExNeu2'),
    study_celltype=c('Marsan_ExNeu1', 'Biogen_ExNeu1', 'Mathys_ExNeu1',
                     'Marsan_ExNeu2', 'Biogen_ExNeu2', 'Mathys_ExNeu2')
)

# Specify column names to subset barcodes
# NOTE: Set to NULL if unnecessary
subset_col <- 'study_celltype'
sample_col <- 'SampleID_celltype'
celltype_col <- 'cell_type'
disease_col <- "general_disease"

# Specify DE thresholds
lfc_thresh <- 0
alpha <- 0.1

# Specify CE target genes
ce_targets <- config_yaml[['genes']]
```

# Loading input data {.tabset}

The number of splicing junctions was counted based on cellranger-aligned reads mapped to the following
genes:

```{r genes_tested}
print(ce_targets)
```

Raw junction counts were compiled into a junction-by-barcode matrix for differential testing in the
previous analysis, [`sc-exploratory.html`](sc-exploratory.html). This matrix was preprocessed
to aggregate the counts per sample per celltype, along with their associated metadata table.
These preprocessed matrices and metadata are imported from the following location:

```{r infile_info}
print(in_rds)
```

```{r import_adata}

# --------------------------------------------------------------------------------
# This chunk imports input data saved in the previous single-cell 
# exploratory analysis. Manually edit the following code if necessary.
# --------------------------------------------------------------------------------

# Import input RDS file
obj <- readRDS(in_rds)

# Extract raw count matrices
mat_list <-  map(obj[['bulk']], ~.x[['raw']])

# Extract the entire sampletable (Edit manually if necessary)
sampletable <- obj[['meta']] %>%
    remove_rownames() %>%
    mutate(SampleID_celltype=paste0(SampleID, "_", cell_type), 
           study_disease_specific_celltype=paste0(study_specific_disease_specific,
                                                  "_",
                                                  cell_type))

# Ensure to have correct levels for each factor columns
for (f in names(factor_groups)) {
    sampletable[[f]] <- factor(sampletable[[f]], levels=factor_groups[[f]])
}


# Prep a list of metadata tables for each subset
coldata_list <- mclapply(mat_list, function(m) { 
    # Splice the metadata table based on samples in the matrix
    cdata <- sampletable[sampletable[[sample_col]] %in% colnames(m),
                         c(sample_col, names(factor_groups))] %>%
        unique()
    # Break if columns of the matrix and rows of the metadata don't match
    if (nrow(cdata) != ncol(m)) {
        stop("Rownames of coldata and colnames of matrix should be the same!")
    }
    # Reorder rows of the subsetted metadata table
    rownames(cdata) <- cdata[[sample_col]]
    cdata <- cdata[colnames(m),]
    return(cdata)
})
```

# Subsets {.tabset}

The subset-wise aggregation was performed as summarized below:

```{r subset_overview, results='asis'}

# --------------------------------------------------------------------------------
# This chunk explores the number of samples and metadata info across the subsets
# --------------------------------------------------------------------------------

# Function to summarize the number of samples (N)
summarize_N <- function(meta_df) {

    # Count the number of samples
    n_df <- meta_df %>%
        group_by_at(vars(subset_col, disease_col)) %>%
        summarize(N=n()) %>%
        spread(disease_col, N)
    # Reorder columns
    disease_order <- factor_groups[[disease_col]][factor_groups[[disease_col]] %in% 
                                                  colnames(n_df)]
    n_df <- n_df[, c(subset_col, disease_order)]
    # Replace missing values with zero
    n_df[is.na(n_df)] <- 0
    # Add a new column for all N
    n_df[['all_N']] <- rowSums(n_df[, colnames(n_df)[-1]])

    return(n_df)
}

for (name in names(coldata_list)) {

    df <- coldata_list[[name]] %>%
        remove_rownames()
    cat("##", name, "{.tabset}\n\n")
    cat("### N\n\n")
    # Prep the summary table for N
    n_df <- summarize_N(df)

    # Print tables
    print(knitr::kable(n_df))
    cat('\n\n')

    cat("### Full table\n\n")
    subchunkify(paste0(name, "_subset_N_unfiltered"))
    csv_path <- file.path(out_dir,
                          paste0(name, '_unfiltered_sampletable.csv'))
    write.csv(df,
              csv_path,
              row.names=FALSE,
              quote=FALSE)

    link_table(csv_path)
    cat('\n\n')
}
```

# Pre-filtering nonzero samples {.tabset}

Samples with zero junction counts are removed from each subset. The number of samples before
and after filtering is summarized below.


```{r prefilter_samples, results='asis'}

# --------------------------------------------------------------------------------
# This chunk filters nonzero-count samples
# --------------------------------------------------------------------------------

for (name in names(mat_list)) {
    cat("##", name, "{.tabset}\n\n")
    # Remove zero-count samples from the count matrix
    m <- mat_list[[name]]
    nonzero_samples <- colSums(m) > 0
    m <- m[, nonzero_samples]
    mat_list[[name]] <- m
    # Remove zero-count samples from the metadata table
    cdata_old <- coldata_list[[name]]
    cdata_new <- cdata_old[colnames(m),]
    coldata_list[[name]] <- cdata_new
    
    cat("### N\n\n")
    n_df <- summarize_N(cdata_new)
    cat("A total of",
        sum(!nonzero_samples),
        "samples are removed from the current subset.",
        "Refer to the following table for remaining samples:")
    print(knitr::kable(n_df))
    cat("\n\n")

    cat("### Full table\n\n")
    subchunkify(paste0(name, "_subset_N_filtered"))
    csv_path <- file.path(out_dir,
                          paste0(name, '_filtered_sampletable.csv'))
    write.csv(df,
              csv_path,
              row.names=FALSE,
              quote=FALSE)

    link_table(csv_path)
    cat('\n\n')
}

```


# Quality control (QC)


## Sample similarity heatmap {.tabset}

Sample-to-sample similarity in junction profiling is explored using a heatmap of normalized counts 
(log2 scale), with *Euclidean distance* represented by the color scale. Darker blue indicates
less distance (i.e., greater similarity) in splice junction profiling.

```{r qc_heatmap, results='asis', fig.height=8, fig.width=8}

# --------------------------------------------------------------------------------
# This chunk explores sample similarity using heatmap
# --------------------------------------------------------------------------------

# Run log2(raw_counts + 1) transformation
l2t_list <- map(mat_list, ~log2(.x + 1))

for (name in names(l2t_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Prep a matrix
    scmat <- l2t_list[[name]] %>%
        t() %>%
        dist() %>%
        as.matrix()

    # Set color to be displayed
    colors <- colorRampPalette(rev(RColorBrewer::brewer.pal(9, 'Blues')))(255)

    # Prep metadata for heatmap
    h_meta <- coldata_list[[name]]
    h_meta <- h_meta[, c(disease_col, subset_col)]
    h_meta <- h_meta[, colnames(h_meta) != sample_col]

    # Print heatmap
    print(pheatmap::pheatmap(
        scmat,
        scale='none',
        color=colors,
        annotation_col=h_meta,
        show_rownames=FALSE,
        show_colnames=FALSE,
        cluster_cols=TRUE,
        border_color=NA
    )
    )
    cat('\n\n')
}

```

## PCA {.tabset}

Another way of looking at sample clustering is principal components analysis (PCA). Each axis does
not have units, rather, it represents the dimensions along which the samples vary the most. The amount 
of variance explained by each principal component is indicated in the axes label.

```{r qc_pca, results='asis'}

# --------------------------------------------------------------------------------
# This chunk explores sample similarity using PCA
# --------------------------------------------------------------------------------

for (name in names(l2t_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Prep a matrix
    scmat <- l2t_list[[name]] %>%
        t()

    # Prep metadata
    p_meta <- coldata_list[[name]]

    # Run PCA
    pca <- prcomp(scmat, center=TRUE, scale=FALSE)
    # Calculate variance explained by each PC
    var_exp <- round(pca$sdev^2/sum(pca$sdev^2) * 100, 2)

    # Prep input dataframe for plotting
    df <- pca$x[,1:2] %>%
        as.data.frame() %>%
        rownames_to_column(sample_col) %>%
        left_join(p_meta, by=sample_col)
    # Prep titles for axes
    axis_titles <- map_chr(
        1:2,
        ~paste0("PC ", .x, " (", var_exp[.x], "%)")
    )

    # Plot PCA
    condition_cols <- colnames(p_meta)[-1] %>%
        sapply(function(c) length(unique(p_meta[[c]])) > 1)
    condition_cols <- colnames(p_meta)[-1][condition_cols]
    for (c in condition_cols) {
        cat('####', c, '\n\n')
        p <- ggplot(df,
                    aes_string(x='PC1',
                               y='PC2',
                               color=c,
                               shape=celltype_col)) +
            geom_point(alpha=0.7, size=3) +
            theme_bw() +
            xlab(axis_titles[1]) +
            ylab(axis_titles[2])

        print(p)
        cat('\n\n')
    }
}

```


# Differential testing {.tabset}

We perform pairwise differential testing using Fisher's exact test. This analysis examines whether
_detection_ of each junction is associated with the disease condition, using binary count matrices with 
1 for detected and 0 otherwise. We aim to determine whether junction detection is significantly 
more frequent in one condition than in the other.

```{r prep_fishers_exact_test}

# --------------------------------------------------------------------------------
# This chunk preps fisher's exact test 
# --------------------------------------------------------------------------------

# Binarize each count matrix (1 for detected, 0 for undetected) - individual junctions
bj_list <- mclapply(mat_list, function(m) ifelse(m > 0, 1, 0))

# Binarize each count matrix (1 for detected, 0 for undetected) - individual junctions for exon type 
be_list <- mclapply(mat_list, function(m) {
    as.data.frame(m) %>%
        rownames_to_column('junction') %>%
        mutate(exon_type=ifelse(str_detect(junction, "non-cryptic"),
                                "junction detected without CE",
                                "CE detected")) %>%
        pivot_longer(!c(junction, exon_type),
                     names_to="sample",
                     values_to="counts") %>%
        group_by(exon_type, sample) %>%
        summarize(counts=sum(counts)) %>%
        mutate(counts=ifelse(counts > 0, 1, 0)) %>%
        pivot_wider(names_from=sample, values_from=counts) %>%
        column_to_rownames('exon_type') %>%
        as.matrix()
    })

# Specify subsets to be analyzed
pairwise_subsets <- names(bj_list)[!str_detect(names(bj_list), "all")]

# Function to run Fisher's exact test and summarize the results in a data frame
fisher_exact_in_df <- function(mat, group_labs) {

    # Run Fisher's exact test for each junction (row) and return a p-value
    mclapply(1:nrow(mat), function(i) {
        # Subset a row
        mat_i <- mat[i, ]
        # Prep a contingency table
        tab_i <- table(mat_i, group_labs)
        # Run a fisher's exact test
        p_value <- ifelse(nrow(tab_i) < 2, 1, fisher.test(tab_i)$p.value)

        # Calculate detection rates
        d_rate <- map(unique(group_labs),
                      ~sum(mat_i[group_labs == .x] / sum(group_labs == .x))) %>%
                set_names(unique(group_labs))

        # Output data frame for p-values and detection rates
        res <- data.frame(pvalue=p_value)
        for (g in names(d_rate)) res[[g]] <- d_rate[[g]]

        return(res) }) %>%
        bind_rows() 
}

# Function to prep a cleaned data frame from the Fisher's exact test results
clean_fisher_exact_res <- function(mat, stats_df, group_labs) {
    # Build a summary data frame
    f_df <- cbind(data.frame(subset=rep(name, nrow(mat)),
                             junction=rownames(mat)),
                  stats_df) %>%
            mutate(FDR=p.adjust(pvalue, method="BH"))

    # Add a column for relative detection rates
    group_order <- levels(group_labs)[levels(group_labs) %in% group_labs]
    f_df[['relative_detection']] <- f_df[[group_order[2]]] / f_df[[group_order[1]]]
    f_df[['relative_detection']] <- ifelse(
        is.infinite(f_df[['relative_detection']]),
        NA,
        f_df[['relative_detection']])

    # Add a column for the number of samples (N)
    for (g in group_order) {
        f_df[[paste0(g, "_N")]] <- table(group_labs)[g]
    }
    f_df <- f_df[, c("subset",
                     "junction", 
                     colnames(f_df)[str_detect(colnames(f_df), "N")],
                     group_order,
                     'relative_detection',
                     "pvalue",
                     "FDR")]
    return(f_df)
}

```

Metrics:

- **subset**: study and celltype
- **junction**: 
    - junction by junction type: `<chr>:<start>:<end>:<gene_name>:<junction_category>`
    - junction by exon type: junctions with or without exon detection
- **N**: number of samples per condition
- **Conditions (e.g. Control, FTD, AD)**: detection rate within each condition calculated by
  the number of samples with detection divided by N
- **relative_detection**: detection rate in disease divided by detection rate in control
- **pvalue**: raw p-values
- **FDR**: false discovery rate (FDR) computed using the Benjamini-Hochberg (BH) method

```{r differential_full, results='asis'}

# --------------------------------------------------------------------------------
# This chunk displays full results for fisher's exact test
# --------------------------------------------------------------------------------

for (name in pairwise_subsets) {
    cat('##', name, '{.tabset}\n\n')

    # Extract metadata 
    meta <- coldata_list[[name]]
    # Extract which column will be compared
    group_labs <- meta[[disease_col]]
    # Extract the count matrix and metadata
    m_list <- list(junction=bj_list[[name]], exon=be_list[[name]])
    # Clean the count matrices after running Fisher's exact test
    m_list <- map(m_list, function(m) {
        stats_df <- fisher_exact_in_df(m, group_labs)
        clean_fisher_exact_res(m, stats_df, group_labs)
    })

    for (datatype in names(m_list)) {
        cat('###', datatype, 'detection\n\n') 
        # Print
        df <- m_list[[datatype]]
        print(knitr::kable(df))
        cat('\n\n')

        # Save
        csv_path <- file.path(
            out_dir, 
            paste0(name, '_differential_results_', datatype, '.csv'))

        write.csv(df, csv_path, row.names=FALSE, quote=FALSE)
        link_table(csv_path)
        cat('\n\n')
    }
}
```

# Session info

```{r session_info, collapse=FALSE}
sessionInfo()
```

