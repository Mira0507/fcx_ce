---
title: "Single cell exploratory analysis on cryptic exons (CEs)"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        toc: true
        toc_float: true
        toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed for exploratory analysis on CE at the single-cell level.


```{r libraries}
# Libraries
library(parallel)
library(tidyverse)
library(ggplot2)
library(ggbeeswarm)
library(reticulate)
library(parallel)
library(yaml)
library(RColorBrewer)
library(plotly)
library(rtracklayer)
library(GenomicRanges)
library(GenomicFeatures)

# Additional options
set.seed(2570)
source('../config/helpers.R')
use_condaenv("../../../menv")

# Specify the number of available cores
n_cores <- future::availableCores()
options(mc.cores=n_cores)

pd <- reticulate::import("pandas")
```

```{python ppackages}
import anndata as ad
import scanpy as sc
import pandas as pd
import numpy as np
import subprocess
import os
```

```{r config}

# --------------------------------------------------------------------------------
# This chunk specifies input paths and variables in R
# --------------------------------------------------------------------------------

# Path to input matrix
mtx_path <- "../results/junction_counts/thalamus_neurons_perind_numers.counts.gz"

# Path to metadata table
meta_path <- "../results/barcodes.tsv"

# Path to GTF
gtf_path <- "../../../input/thalamus_excitatory/genes.gtf.gz"

# Path to Snakemake config
snakemake_config <- "../config/config.yaml"

# Paths to AnnData
adata_paths <- read_yaml(snakemake_config)[['adata']] %>%
    map(~paste0("../", .x))

# Path to output directory
out_dir <- "sc-exploratory"

# Create directories if missing
for (p in c(out_dir)) {
    if (! dir.exists(p)) { dir.create(p, recursive=TRUE) }
}

# Specify metadata columns for factors and factor levels
factor_groups <- list(
    general_disease=c('Control', 'FTD', 'AD'),
    renamed_annotation_cell_type_post_outlier_removal=c( 
        'ExNeu1',
        'ExNeu2',
        'SOX14_Pos_InNeu',
        'SOX14_Neg_InNeu',
        'Mixed'),
    study=c('Marsan', 'Biogen', 'Mathys'),
    study_specific_disease_specific=c(
        'Control-Marsan',
        'Control-Biogen',
        'Control-Mathys',
        'FTD-Marsan',
        'FTD-Biogen',
        'AD-Mathys')
)

# Specify column names to subset barcodes
# NOTE: Set to NULL if unnecessary
celltype_col <- 'renamed_annotation_cell_type_post_outlier_removal'
disease_col <- 'general_disease'
subset_col <- list(disease_celltype=c(disease_col, celltype_col))
sample_col <- 'SampleID'
study_col <- 'study'

# Specify genes explored in the current analysis
genes <- read_yaml(snakemake_config)[['genes']] 

# Specify HEX color code
color_map <- list(
    general_disease=c(
        Control="#6666FF",
        FTD="#669900",
        AD="#FF6600"),
    study=c(
        Marsan="#FF00FF",
        Biogen="#00FFFF",
        Mathys="#BFBFBF"),
    cell_type=c(
        ExNeu1="#90C6E2",
        ExNeu2="#547CB2", 
        SOX14_Pos_InNeu="",
        SOX14_Neg_InNeu="",
        Mixed=""))
        # Astrocyte="#ABD158",
        # BVC="#74858C",
        # CP="#D5C18E",
        # InNeu1="#21409A",
        # InNeu2="#262262",
        # Lymphocyte="#68151F",
        # Microglia="#D24A75",
        # OL="#FDB515",
        # OPC="#ED7020",
        # PVM="#231F20")
```

# Loading input data {.tabset}

The number of splicing junctions was counted based on cellranger-aligned reads mapped to the following
genes:

```{r genes_tested}
print(genes)
```

These counts were compiled into a junction-by-barcode matrix for differential testing.


```{python import_adata}

# --------------------------------------------------------------------------------
# This chunk imports input data and add the junction matrix to AnnData
# --------------------------------------------------------------------------------

# reticulate::repl_python()

# Import AnnData objects
adata_dic = {celltype: ad.read_h5ad(path) for celltype, path in r.adata_paths.items()}

# Import junction matrix and metadata
counts = pd.read_csv(r.mtx_path, sep=" ")

```

# Annotating input junctions

The following junctions were detected in the input single-cell datasets. Splice junctions 
are annotated as summarized below:

* Known start and end coordinates of all exons are labeled as _boundaries_.

* The _splice_type_ annotation is defined as follows:
    * _non-cryptic_: both the start and end coordinates of the junction match the _boundaries_.
    * _cryptic_start_: only the end coordinate of the junction matches the _boundaries_.
    * _cryptic_end_: only the start coordinate of the junction matches the _boundaries_.
    * _cryptic_both_: neither the start nor the end coordinates of the junction match the _boundaries_.

* The _exon_type_ annotation is defined as follows:
    * _non-cryptic-annotated_: both the start and end of the junction are at annotated positions
    * _non-cryptic-novel_: neither coordinate of the junction is within an intron AND either position is
      at non-annotated positions
    * _cryptic_: one or both of the start and end coordinates of the junction is within intron regions

<img src="junction_exon.png" width="600">

Refer to the following annotation table, which includes a toy junction at `chr8:79611214:79636812`.
This junction hypothetically ends in an exon.


```{r annotate_junctions, results='asis', cache=TRUE}

# --------------------------------------------------------------------------------
# This chunk annotates input junctions
# --------------------------------------------------------------------------------

# Import GTF annotation
gtf <- import(gtf_path)

# Build TxDb from GRanges
txdb <- txdbmaker::makeTxDbFromGRanges(gtf)

# Obtain ranges for introns
introns <- intronsByTranscript(txdb, use.names=TRUE) %>%
    unlist(use.names=FALSE)

# Prep a data frame consisting of genomic coordinates for splice start and end sites
junctions <- data.frame(junctions=rownames(py$counts)) %>%
    separate(junctions, c('chr', 'start', 'end'), sep=":") %>%
    mutate_at(c('start', 'end'), as.numeric)

########## THIS IS A TOY COORDINATE WITH ITS END SITE MATCHING EXONIC REGION OF STMN2 ###
########## COMMENT OUT AFTER VALIDATION! ################################################

junctions <- rbind(junctions,
                   data.frame(chr='chr8', start=79611214, end=79636812))

########################################################################################

# Convert the data frame into GRanges obj
junctions_gr <- GRanges(
    seqnames=junctions$chr,
    ranges=IRanges(start=junctions$start, end=junctions$end))

# Annotate gene names
hits <- findOverlaps(junctions_gr, gtf, type= "within")
annotated <- queryHits(hits)
junctions[['gene_name']][annotated] <- sapply(
    subjectHits(hits),
    function(x) mcols(gtf)$gene_name[x])

# Filter GTF by genes and structure of interest
gtf <- gtf[gtf$type == "exon" & gtf$gene_name %in% genes]

# Extract annotated splice sites in any direction for genes of interest
# These splice sites are the start and end coordinates of individual exons
boundaries <- c(
    GRanges(seqnames=seqnames(gtf),
            ranges=IRanges(start=start(gtf), end=start(gtf))),
    GRanges(seqnames=seqnames(gtf),
            ranges=IRanges(start=end(gtf), end=end(gtf)))
) %>%
as.data.frame() %>%
dplyr::select(seqnames, start) %>%
set_names(c('seqnames', 'splice_sites'))

# Add a column indicating the type of splicing based on whether the start 
# end coordinates of junctions match the annotated splice sites
junctions[['splice_type']] <- 
    ifelse(! junctions[['start']] %in% boundaries[['splice_sites']],
           "cryptic_start",
    ifelse(! junctions[['end']] %in% boundaries[['splice_sites']],
           "cryptic_end",
     ifelse(! junctions[['start']] %in% boundaries[['splice_sites']] &
            ! junctions[['end']] %in% boundaries[['splice_sites']],
            "cryptic_both",
           "non-cryptic")))

# Add a column indicating the type of exons generated by each junction. This step aims 
# to identify whether each cryptic splicing generates cryptic exons. For example, cryptic
# exons are generated when either donor or acceptor site of junctions is within
# intronic regions.
junctions[['exon_type']] <- sapply(1:nrow(junctions), function(i) {
    # Return "non-cryptic" if the splice junction starts and ends at annotated sites
    etype <- if (junctions[i, 'splice_type'] == 'non-cryptic') {
        "non-cryptic-annotated"
    } else {
        # Build GRanges obj for start and end coordinates
        start_gr <- GRanges(seqnames=junctions[i, 'chr'],
                            ranges=IRanges(start=junctions[i, 'start'],
                                           end=junctions[i, 'start']))
        end_gr <- GRanges(seqnames=junctions[i, 'chr'],
                          ranges=IRanges(start=junctions[i, 'end'],
                                         end=junctions[i, 'end']))
        # Return "non-cryptic" if none of the coordinates match intronic regions 
        # and "cryptic" otherwise.
        etype <- ifelse(overlapsAny(start_gr, introns) | 
                        overlapsAny(end_gr, introns),
                        "cryptic",
                        "non-cryptic-novel")
    }
    return(etype) })

DT::datatable(junctions)

# Add a column for junction ids
junctions[['junction_id']] <- paste(
    junctions$chr,
    junctions$start,
    junctions$end,
    junctions$gene_name,
    junctions$exon_type,
    sep=":"
) 

# Delete the toy junction
junctions <- junctions[1:nrow(junctions)-1,]
```

```{python ann_data}

# --------------------------------------------------------------------------------
# This chunk prepares subsetted AnnData
# --------------------------------------------------------------------------------

# Replace index with junction ids
counts.index = r.junctions['junction_id']

# reticulate::repl_python()

for celltype in adata_dic.keys():

    # Retrieve an AnnData corresponding to the celltype
    ann = adata_dic[celltype]
    # Extract obj metadata
    obs = ann.obs
    # Impute missing values of the metadata manually
    obs['study_specific_disease_specific'] = obs['general_disease'].astype(str) + '-' + obs['study'].astype(str)

    # Add new columns required to subset barcodes if necessary
    if r.subset_col is not None:
        for key, value in r.subset_col.items():
            obs[key] = obs[value].astype(str).agg(":".join, axis=1)

    # Replace the input metadata with updated one
    ann.obs = obs
    # Add raw and log1p-transformed junction counts to the AnnData
    ann.obsm['junction_raw'] = counts[obs.index].T
    ann.obsm['junction_lognorm'] = np.log1p(counts[obs.index].T)
    # Update the input AnnData
    adata_dic[celltype] = ann

    # Extract cell barcodes
    target_cells = list(ann.obs.index)
    # Slice the junction count matrix based on the extracted barcodes
    counts_subset = counts[target_cells]
    # Subset metadata
    obs_subset = obs.loc[counts_subset.columns, :]

    # Create a new AnnData obj
    ann_new = ad.AnnData(X=counts_subset.T, obs=obs_subset)
    ann_new.layers['counts'] = ann_new.X.copy()
    # Add log1p-transformed values to the AnnData
    sc.pp.log1p(ann_new)
    ann_new.layers['lognorm'] = ann_new.X.copy()

    # Specify paths to updated/created AnnData
    updated_path = f"{r.out_dir}/{celltype}_JUNCTIONS_ADDED.h5ad"
    new_path = f"{r.out_dir}/{celltype}_JUNCTIONS_ONLY.h5ad"
    # Save updated/created AnnData
    ann.write_h5ad(updated_path)
    ann_new.write_h5ad(new_path)

```

Input AnnData objects for each celltype:

```{r infile_info}

for (name in names(adata_paths)) {
    print(paste0(name, ": ", adata_paths[[name]]))
}

```

These input objects have been updated to include the following data:

- `AnnData.obsm["junction_raw"]`: raw junction counts
- `AnnData.obsm["junctions_lognorm"]`: log-normalized junction counts (log1p transformation)

Refer to the following file paths for the updated `AnnData` objects:

```{r outann_info1}
for (name in names(adata_paths)) {
    print(paste0(name, ": ", out_dir, "/", name, "_JUNCTIONS_ADDED.h5ad"))
}
```

In the meantime, new `AnnData` objects have been saved as listed below:

- `AnnData.layers["counts"]`: raw junction counts
- `AnnData.layers["lognorm"]`: log-normalized junction counts (log1p transformation)

The newly created `AnnData` objects are saved at:

```{r outann_info2}
for (name in names(adata_paths)) {
    print(paste0(name, ": ", out_dir, "/", name, "_JUNCTIONS_ONLY.h5ad"))
}
```

Note that the `*_JUNCTIONS_ADDED.h5ad` file includes both the transcript and junction counts, while
the `*_JUNCTIONS_ONLY.h5ad` contains only junction counts. 

The following table shows the number of samples and barcodes for each study- and celltype-specific subset.
The `N_samples` and `N_barcodes` columns represent the number of samples and barcodes 
that were initially loaded, respectively.

```{r n_barcodes, results='asis'}

# --------------------------------------------------------------------------------
# This chunk displays the number of input barcodes for each subset
# --------------------------------------------------------------------------------

# Function to extract the number of samples from a list of AnnData obj
count_n_samples <- function(obj_dic) {
    sapply(obj_dic, function(obj) obj$obs[[sample_col]]) %>%
        unlist() %>%
        unique() %>%
        length()
}

# Prep an data frame exploring the number of samples and barcodes for all cells
n_df <- data.frame(subset="all",
                   N_samples=count_n_samples(py$adata_dic),
                   N_barcodes=sapply(py$adata_dic, function(o) nrow(o$obs)) %>% sum
)

# Add rows for each cell type in all datasets
df <- lapply(py$adata_dic, function(o) as.data.frame(o$obs)) %>%
    bind_rows()
ncells <- split(df, df[[celltype_col]]) %>% 
    sapply(nrow)
nsamples <- split(df, df[[celltype_col]]) %>%
    map_dbl(~.x[, c(celltype_col, sample_col)] %>%
        unique() %>%
        nrow())

n_df <- rbind(n_df,
              data.frame(subset=paste0("all:", names(ncells)),
                         N_samples=nsamples,
                         N_barcodes=ncells) %>%
              remove_rownames()
)

# Add rows for dataset-specific celltypes
for (o in py$adata_dic) {
    df <- as.data.frame(o$obs)
    n_list <- split(df, df[[names(subset_col)[1]]]) %>%
        lapply(nrow)
    n_df <- rbind(n_df,
                  data.frame(subset=names(n_list), 
                             N_samples=count_n_samples(list(o)),
                             N_barcodes=unlist(n_list)))
}
n_df <- n_df %>% remove_rownames()

knitr::kable(n_df)
```

```{r prep_count_list}

# --------------------------------------------------------------------------------
# This chunk concatenates metadata across datasets
# --------------------------------------------------------------------------------

# Concatenate metadata for all barcodes
all_meta <- lapply(py$adata_dic, function(o) o$obs %>% as.data.frame()) %>%
    bind_rows()

# Reorder rows to align with the count matrix
all_meta <- all_meta[colnames(py$counts),]

```

```{python prep_subset_obj}

# --------------------------------------------------------------------------------
# This chunk is used to manually subset AnnData objects
# --------------------------------------------------------------------------------

# reticulate::repl_python()

# Function to normalize and reducing dimensions on an AnnData obj
def preprocess_adata(obj):
    # Normalize counts
    obj.layers['counts'] = obj.X.copy()
    sc.pp.log1p(obj)
    obj.layers['lognorm'] = obj.X.copy()
    # Run PCA
    sc.tl.pca(obj)
    # Find neighbors
    sc.pp.neighbors(obj)
    # Run UMAP
    sc.tl.umap(obj)

    return obj

# Initialize a new dictionary for subsetted AnnData
subadata_dic = {'all': preprocess_adata(ad.AnnData(X=counts.T, obs=r.all_meta))}

subset_col = list(r.subset_col.keys())[0]
celltype_col = r.celltype_col

for subs in r.n_df['subset'][1:]:
    # Specify key column
    if "all" in subs:
        key_col = celltype_col
        target = subs.split(":")[1]
    else:
        key_col = subset_col
        target = subs

    # Retrieve metadata for the subset
    obs_x = r.all_meta[r.all_meta[key_col] == target]
    # Prep the subsetted count matrix
    mat_x = counts[obs_x.index]
    # Create an AnnData obj
    adata_x = ad.AnnData(X=mat_x.T, obs=obs_x)
    # Add log-normalized and dim-reduced AnnData to the dictionary
    subadata_dic[subs] = preprocess_adata(adata_x)

```

```{r aggr_counts}

# --------------------------------------------------------------------------------
# This chunk prepares a list of matrices with columns for barcodes or samples
# --------------------------------------------------------------------------------

# Create 
sc_list <- list()
sp_list <- list()

for (name in names(py$subadata_dic)) {

    # Retrieve an AnnData obj
    o <- py$subadata_dic[[name]]

    # Prep matrices for raw and normalized junction counts per barcode
    mat_list <- list(raw=o$layers[['counts']], norm=o$layers[['lognorm']]) %>%
        lapply(t) %>%
        lapply(function(m) {
            colnames(m) <- rownames(o$obs)
            rownames(m) <-o$var_names$values
            return(m)
        })
    sc_list[[name]] <- mat_list

    # Collapse the single cell matrix to the following dimension: junction-by-sample
    mat2_list <- mclapply(names(mat_list), function(ctype) {
        mat <- mat_list[[ctype]] %>%
            as.data.frame() %>%
            rownames_to_column('junction') %>%
            pivot_longer(!junction, names_to='barcodes', values_to='junction_counts') %>%
            left_join(o$obs %>% rownames_to_column('barcodes'), by="barcodes") %>%
            as.data.frame() %>%
            unite(col="SampleID_celltype",
                  sample_col,
                  celltype_col,
                  sep="_",
                  remove=FALSE) %>%
            dplyr::select(junction, barcodes,
                          junction_counts,
                          SampleID_celltype) %>%
            group_by(junction, SampleID_celltype) %>%
            summarize(counts=sum(junction_counts)) %>%
            spread(SampleID_celltype, counts) %>%
            column_to_rownames('junction')
        # Break if missing values have been introduced to the collapsed matrix
        if (any(is.na(mat))) { 
            paste0(name, ": Missing values introdueced to ", ctype, " counts!") 
        }

        return(mat)
    }) %>%
    set_names(names(mat_list))

    sp_list[[name]] <- mat2_list
}

```

# Quality Control (QC)

## Proportion of cells with junctions

The number of barcodes is counted based on whether junctions were detected in each cell. Refer to 
the following columns for the overview:

- `N_barcodes`: all input barcodes
- `N_barcodes_junctions`: barcodes in which *any junctions* were detected
- `percentage`: `N_barcodes_junctions / N_barcodes x 100`, representing the proportion
  of barcodes with junction detection

```{r n_barcodes_junctions, results='asis'}

# --------------------------------------------------------------------------------
# This chunk displays the number of barcodes with and without junction detection
# --------------------------------------------------------------------------------
n_df <- n_df %>%
    dplyr::select(-N_samples) %>%
    mutate(N_barcodes_junctions=sapply(py$subadata_dic,
                                       function(o) sum(rowSums(o$X) > 0)),
           percentage=N_barcodes_junctions/N_barcodes * 100,
           percentage=round(percentage, 2))

knitr::kable(n_df)
```

## Heatmap {.tabset}

Cell-to-cell similarity in junction profiling is explored using a heatmap generated from non-zero cells, 
with *Euclidean distance* represented by the color scale. Darker blue indicates less distance 
(i.e., greater similarity) in splice junction profiling.

```{r function_for_plotting}

# Function cleaning metadata based on available columns
clean_metadata <- function(data_frame, col_filter) {
    df_updated <- data_frame[, col_filter]
    return(list(df=df_updated, cols=col_filter))
}
```

```{r qc_heatmap, results='asis', fig.height=12, fig.width=12}

# --------------------------------------------------------------------------------
# This chunk creates cell-to-cell similarity heatmap
# --------------------------------------------------------------------------------

for (name in names(sp_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Retrieve the raw count matrix
    scmat <- sc_list[[name]][['raw']]
    # Remove zero-count barcodes
    scmat <- scmat[, colSums(scmat) > 0]
    # Transform to a distance matrix after applying log2 transformation
    # with a pseudocount of 1
    scmat <- as.matrix(dist(t(log2(scmat + 1))))

    # Set color to be displayed
    colors <- colorRampPalette(rev(RColorBrewer::brewer.pal(9, 'Blues')))(255)

    # Prep metadata for heatmap
    heatmap_meta <- as.data.frame(py$subadata_dic[[name]][['obs']]) %>%
        unite(col="SampleID_celltype",
              sample_col,
              celltype_col,
              sep="_",
              remove=FALSE) 
    heatmap_meta <- clean_metadata(
        data_frame=heatmap_meta,
        col_filter=c(names(subset_col)[1], names(factor_groups)))[['df']]

    # Print heatmap
    print(pheatmap::pheatmap(
        scmat,
        scale='none',
        color=colors,
        annotation_col=heatmap_meta,
        show_rownames=FALSE,
        show_colnames=FALSE,
        cluster_cols=TRUE,
        border_color=NA
    )
    )
    cat('\n\n')
}
```

## PCA {.tabset}

Another way of looking at sample clustering is principal components analysis (PCA). Each axis does 
not have units, rather, it represents the dimensions along which the samples vary the most. 
The amount of variance explained by each principal component is indicated in the axes label.

```{r pca, results='asis', fig.width=8}

# --------------------------------------------------------------------------------
# This chunk creates PCA plots across the  cells
# --------------------------------------------------------------------------------

for (name in names(sp_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Retrieve the raw count matrix
    scmat <- sc_list[[name]][['raw']]
    # Remove zero-count barcodes and apply log2-transformation
    scmat <- t(log2(as.matrix(scmat[, colSums(scmat) > 0] + 1)))
    # Prep metadata
    meta_data <- clean_metadata(
        as.data.frame(py$subadata_dic[[name]][['obs']]),
        c(names(subset_col)[1], names(factor_groups)))
    m_df <- meta_data[['df']] %>%
        rownames_to_column('barcode')
    # Run PCA
    pca <- prcomp(scmat, center=TRUE, scale=FALSE)
    # Calculate variance explained by each PC
    var_exp <- round(pca$sdev^2/sum(pca$sdev^2) * 100, 2)
    # Prep input dataframe for plotting
    df <- pca$x[,1:2] %>%
        as.data.frame() %>%
        rownames_to_column('barcode') %>%
        left_join(m_df, by='barcode')
    # Prep titles for axes
    axis_titles <- map_chr(
        1:2,
        ~paste0("PC ", .x, " (", var_exp[.x], "%)")
    )

    # Plot PCA
    condition_cols <- meta_data[['cols']]
    for (c in condition_cols) {
        cat('####', c, '\n\n')
        p <- ggplot(df,
                    aes_string(x='PC1',
                               y='PC2',
                               color=c)) +
            geom_point(alpha=0.7, size=3) +
            theme_bw() +
            xlab(axis_titles[1]) +
            ylab(axis_titles[2])

        if (c %in% names(color_map)) {
            p <- p + scale_color_manual(values=color_map[[c]])
        }

        print(p)
        cat('\n\n')
    }
}



```

## UMAP {.tabset}

Junction profiling is explored across cells on UMAP. Each dot represents a single cell,
along with color codes corresponding to different conditions.


```{r qc_umap, results='asis', fig.height=8, fig.width=8}

# --------------------------------------------------------------------------------
# This chunk plots UMAP embedding
# --------------------------------------------------------------------------------

for (name in names(py$subadata_dic)) {
    cat('###', name, '{.tabset}\n\n')
    # Extract UMAP coordinates
    o <- py$subadata_dic[[name]]
    df <- o[['obsm']][['X_umap']][, 1:2] %>%
        as.data.frame() %>%
        set_names(c('UMAP1', 'UMAP2'))
    # Prep metadata
    meta_data <- clean_metadata(
        as.data.frame(py$subadata_dic[[name]][['obs']]),
        c(names(subset_col)[1], names(factor_groups)))
    m_df <- meta_data[['df']]
    # Add metadata columns to the UMAP coordinates
    df <- cbind(df, m_df) %>%
        rownames_to_column('barcode')

    condition_cols <- meta_data[['cols']]
    for (c in condition_cols) {
        cat('####', c, '\n\n')
        p <- ggplot(df,
                    aes_string(x='UMAP1',
                               y='UMAP2',
                               color=c)) +
            geom_point(alpha=0.7, size=1) +
            theme_bw()

        if (c %in% names(color_map)) {
            p <- p + scale_color_manual(values=color_map[[c]])
        }

        print(p)
        cat('\n\n')
    }
}
```

## Junction count distribution {.tabset}

Junction counts are explored per cell across the conditions. These junctions include both annotated
and cryptic types.


```{r junction_count_distribution, results='asis'}

# --------------------------------------------------------------------------------
# This chunk displays the number of junction counts per cell across the conditions
# --------------------------------------------------------------------------------

for (name in names(sc_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Extract normalized junction count matrix
    mat <- sc_list[[name]][['norm']]
    counts_df <- data.frame(barcodes=colnames(mat),
                            counts=colSums(mat)) %>%
        remove_rownames()
    # Prep metadata
    meta_data <- clean_metadata(
        as.data.frame(py$subadata_dic[[name]][['obs']]),
        c(names(subset_col)[1], names(factor_groups)))
    m_df <- meta_data[['df']] %>%
        rownames_to_column('barcodes')
    condition_cols <- meta_data[['cols']]

    # Add metadata columns to the count data frame
    counts_df <- counts_df %>%
        left_join(m_df, by="barcodes")
    for (c in condition_cols) {
        cat('\n\n####', c, '\n\n')
        p <- ggplot(counts_df, aes_string(x=c, y='counts', fill=c)) +
            geom_violin(trim=TRUE) +
            geom_boxplot(fill="white", width=0.1) +
            theme_bw() +
            ylab('Normalized Junction Counts per Cell') +
            scale_y_log10() +
            theme(axis.title.x=element_blank(),
                  axis.text.x=element_text(angle=90, vjust=0.5, hjust=1)) 

        if (c %in% names(color_map)) {
            p <- p + scale_fill_manual(values=color_map[[c]])
        }

        print(p)
        cat('\n\n')
    }
}

```

# Cells with and without CE

## UMAP {.tabset}

The following UMAPs display individual cells with and without CEs. Refer to the following detection
criteria:

- *CE detected*: the counts of CEs in the *exon_type* is greater than 0
- *junction detected without CE*: splice junctions are detected with no CEs
- *junction undetected*: none of the splice junctions are detected

```{r umap_prep}

# --------------------------------------------------------------------------------
# This chunk specifies variables and a function required to generate UMAPs
# --------------------------------------------------------------------------------

# Specify plotting options
exon_levels <- list(factors=c('CE detected',
                              'junction detected without CE',
                              'junction undetected'),
                    colors=c("#6A5ACD",
                             "#DA70D6",
                             "grey"))
names(exon_levels[['colors']]) <- exon_levels[['factors']]

# Function to label each exon based on the counts of cryptic splicing
label_exon <- function(data_frame) {
    # Add a column for temporary labels for exons generated by each splice junctions
    res <- mclapply(1:nrow(data_frame), function(i) {
        e_code <- ""
        for (c in c('cryptic', 'non-cryptic-annotated', 'non-cryptic-novel')) {
            if (c %in% colnames(data_frame)[-1]) {
                new_code <- ifelse(data_frame[i, c] > 0, c, "")
                e_code <- paste0(e_code, " ", new_code)
                res_data_frame <- data.frame(barcodes=data_frame$barcodes[i],
                                             temp_code=e_code)
            }
        }
        return(res_data_frame)
    }) %>%
    bind_rows() 

    # Ensure to have the same barcode order as the input data frame
    rownames(res) <- res[['barcodes']]
    res <- res[data_frame$barcodes,] %>%
        remove_rownames()

    # Add a column for final exon detection criteria
    exon_vec <- ifelse(
        str_detect(res[['temp_code']], " cryptic "),
        "CE detected",
        ifelse(str_detect(res[['temp_code']], "non-cryptic"),
               "junction detected without CE",
               "junction undetected"))

    return(exon_vec)
}
```


```{r ce_umap, results='asis'}

# --------------------------------------------------------------------------------
# This chunk generates UMAPs color-coding nuclei with and without CEs 
# along with disease status
# --------------------------------------------------------------------------------

for (celltype in names(py$adata_dic)) {
    cat('###', celltype, '{.tabset}\n\n')
    # Extract an AnnData obj
    o <- py$adata_dic[[celltype]]

    # Extract UMAP coordinates
    udf <- o[['obsm']][['X_umap']] %>%
        as.data.frame() %>%
        set_names(c('UMAP1', 'UMAP2')) %>%
        # Add junction counts to the coordinates
        cbind(o[['obsm']][['junction_lognorm']]) %>%
        # Add metadata
        cbind(clean_metadata(
            o[['obs']],
            c(names(subset_col)[1], names(factor_groups)))[['df']])

    udf[[names(subset_col)[1]]] <- o[['obs']][[names(subset_col)[1]]]
    udf[['barcodes']] <- rownames(o[['obs']])

    # Clean the data frame
    udf <- udf %>%
        pivot_longer(cols=starts_with('chr'),
                     names_to='junction',
                     values_to='counts') %>%
        as.data.frame() %>%
        separate(junction, 
             c('chr', 'start', 'end', 'gene', 'exon_type'),
             sep=":") 

    for (gene in genes) {
        cat('####', gene, '{.tabset}\n\n')

        # Subset the data frame for a gene
        gdf <- udf[udf$gene == gene,] %>%
            group_by(barcodes, exon_type) %>%
            summarize(counts=sum(counts)) %>%
            spread(exon_type, counts) %>%
            as.data.frame()

        # Add a column identifying whether each barcode expressed CEs
        gdf[['exon_detection']] <- label_exon(gdf)

        # Add metadata columns back to the data frame
        gdf <- gdf[, c('barcodes', 'exon_detection')] %>%
            inner_join(udf[udf$gene == gene,], by='barcodes') %>%
            dplyr::select(-exon_type, -counts, -chr, -start, -end) %>%
            unique()

        # Break if any missing values are found
        if (any(is.na(gdf))) {
            stop("Missing values introduced to your exon_detection column!")
        }

        gdf_list <- split(gdf, gdf[[names(subset_col)[1]]])
        for (name in names(gdf_list)) {
            cat("#####", name, "{.tabset}\n\n")
            # Print UMAP
            pdf <- gdf_list[[name]]
            cat("###### Junction detection\n\n")
            p <- ggplot(pdf[pdf$exon_detection == "junction undetected",],
                        aes(x=UMAP1, y=UMAP2, color=exon_detection)) +
                geom_point(size=0.5, alpha=0.5) +
                geom_point(data=pdf[pdf$exon_detection != "junction undetected",],
                           aes(x=UMAP1, y=UMAP2, color=exon_detection),
                           size=0.5, alpha=1) +
                theme_classic() +
                scale_color_manual(values=exon_levels[['colors']])
            print(p)
            cat("\n\n")
            cat("###### Disease\n\n")
            p <- ggplot(pdf,
                        aes_string(x='UMAP1', y='UMAP2', color=disease_col)) +
                geom_point(size=0.5) +
                theme_classic() +
                scale_color_manual(values=color_map[[disease_col]])
            print(p)
            cat("\n\n")
        }
    }
}

```

# Expression of genes with and without CEs {.tabset}

The expression of the following genes is compared between cells with and without CEs:

```{r print_genes_expresssed}
gene_expressed <- c(genes, 'TARDBP')
print(gene_expressed)
```

The [Gittings et al. paper](https://doi.org/10.1007/s00401-023-02599-5) suggested that the expression of
the STMN2 gene is lower in cells where the STMN2 CE is detected. We examine whether the same pattern 
is observed across the genes of interest in our datasets. Note that cells are excluded if junctions 
are not detected.

```{r prep_gene_expression, cache=TRUE}

# --------------------------------------------------------------------------------
# This chunk preps to analyzes the expression levels of genes with and without CEs
# --------------------------------------------------------------------------------

# Prep a data frame including metadata, normalized gene expression levels, 
# and normalized junction counts
ad_df <- mclapply(py$adata_dic, function(o) {
    m_df <- clean_metadata(
        o[['obs']],
        c(names(subset_col)[1], names(factor_groups)))[['df']]
    j_df <- o[['obsm']][['junction_lognorm']]
    g_df <- o[, gene_expressed][['layers']][['log-norm']] %>%
        as.matrix() %>%
        as.data.frame() %>%
        set_names(gene_expressed)
    return(do.call("cbind", list(m_df, j_df, g_df)))
}) %>%
bind_rows() %>%
rownames_to_column('barcodes') %>%
pivot_longer(cols=starts_with("chr"),
             names_to="exon_type",
             values_to="junction_counts") %>%
pivot_longer(cols=gene_expressed,
             names_to="gene",
             values_to="gene_exp") %>%
as.data.frame() %>%
separate(exon_type,
         c('chr', 'start', 'end', 'junction', 'exon_type'),
         sep=":") %>%
mutate(gene=factor(gene, levels=gene_expressed))

# Break if any missing values are introduced
if (any(is.na(ad_df))) {
    stop("Check your missing values in ad_df!")
}
```

P-values for the expression differences between cells with and without CEs were calculated 
using a two-sided Wilcoxon Rank Sum test.


```{r plot_expression, results='asis'}

# --------------------------------------------------------------------------------
# This chunk presents the expression of genes with and without CEs
# --------------------------------------------------------------------------------

for (celltype in names(py$adata_dic)) {
    cat('\n\n##', celltype, '{.tabset}\n\n')

    # Subset the data frame by celltype
    celltype_extracted <- py$adata_dic[[celltype]][['obs']][[celltype_col]] %>%
        unique() %>%
        as.character()
    sub_df <- ad_df[ad_df[[celltype_col]] == celltype_extracted,]
    # Prep metadata column names
    meta_cols <- clean_metadata(
        sub_df,
        c(names(subset_col)[1], names(factor_groups)))[['cols']]
    # Split the data frame by junction genes
    sub_list <- split(sub_df, sub_df[['junction']]) %>%
        lapply(function(df) {

            # Clean data frame to count the number of junctions
            df <- df %>%
                group_by(barcodes, exon_type) %>%
                summarize(junction_counts=sum(junction_counts)) %>%
                pivot_wider(names_from=exon_type, values_from=junction_counts)

            # Break if any missing values are introduced
            if (any(is.na(df))) {
                stop("Missing values found!")
            }

            # Add a column for exon detection type
            df[['exon_detection']] <- label_exon(df)
            return(df)
        }) %>%
        # Add gene expression counts and metadata to the subsetted data frame
        mclapply(function(df) df %>%
               dplyr::select(barcodes, exon_detection) %>%
               inner_join(ad_df[ c('barcodes', 'gene', 'gene_exp', meta_cols)],
                          by="barcodes") %>%
               as.data.frame() %>%
               # Remove barcodes with zero junction counts
               dplyr::filter(exon_detection != "junction undetected") %>%
               unique())

        # Reorder elements in the list
        sub_list <- sub_list[genes]

    for (junction in names(sub_list)) {
        cat('\n\n### CE:', junction, '{.tabset}\n\n')
        # Subset further to include only genes to be explored
        genes_i <- c(junction, "TARDBP")
        pdf <- sub_list[[junction]] %>%
            dplyr::filter(gene %in% genes_i)
        # Create a boxplot
        p <- ggplot(pdf, aes(x=exon_detection, y=gene_exp, fill=exon_detection)) +
            geom_violin(trim=TRUE) +
            geom_boxplot(fill="white", width=0.1) +
            theme_bw() +
            facet_wrap(~gene, scales="free_y") +
            theme(axis.title.x=element_blank(),
                  axis.text.x=element_text(angle=90, vjust=0.5, hjust=1)) +
            ylab(paste("Gene Expression (Normalized)")) +
            scale_fill_manual(values=exon_levels[['colors']])
        
        print(p)
        cat('\n\n')

        # Calculate p-values using wilcox test
        ncell_df <- pdf %>%
            group_by(exon_detection, gene) %>%
            summarize(nCell_tested=n()) %>%
            unique() %>%
            arrange(gene)
        print(knitr::kable(ncell_df))
        if (length(unique(pdf$exon_detection)) == 2 & 
            !any(ncell_df$nCell_tested == 1)) {
            for (g in genes_i) {
                pval <- wilcox.test(
                    gene_exp ~ exon_detection,
                    data=pdf[pdf$gene == g,],
                    alternative="two.sided")$p.value
                cat("\n\n*", g, "expression p-value -", pval, "\n\n")
            }
        } else {
            cat("\n\nP-values unavailable...\n\n")
        }
    }
}

```

# Proportion of cells with junction detection {.tabset}

Lastly, we explore various metrics at the single-cell level across samples for each cell subtype 
and junction target gene. 

```{r prep_cell_junction_stat, cache=TRUE}

# --------------------------------------------------------------------------------
# This chunk assesses the number and the proportion of junctions with and without CE per cell
# --------------------------------------------------------------------------------

ncount_list <- list()

# Calculate a pseudo-count for each count type
count_types <- c('junction_raw', 'junction_lognorm')
pseudoc_list <- mclapply(count_types, function(c) {
    # Merge matrices from both units
    m <- map(py$adata_dic, ~.x[['obsm']][[c]]) %>%
        bind_rows()
    min(m[m > 0])
}) %>%
set_names(count_types)

for (celltype in names(py$adata_dic)) {
    # Extract an AnnData obj and the metadata from the obj
    o <- py$adata_dic[[celltype]]
    m_df <- o[['obs']][, c(names(subset_col)[1], sample_col, disease_col, study_col)] %>%
        rownames_to_column('barcodes')
    ncount_list[[celltype]] <- list()
    for(counttype in count_types) {
        c_df <- o[['obsm']][[counttype]] %>%
            as.data.frame() %>%
            rownames_to_column('barcodes') %>%
            pivot_longer(!barcodes,
                         names_to="junction",
                         values_to="counts") %>%
            separate(junction,
                     c('chr', 'start', 'end', 'junction', 'exon_type'),
                     sep=":") %>%
            inner_join(m_df, by="barcodes") %>%
            as.data.frame()

        # Specify a pseudocount
        pseudo_c <- pseudoc_list[[counttype]]
        junction_genes <- unique(c_df[['junction']])
        gdf_list <- mclapply(junction_genes, function(gene) {
            # Subset the data frame by junction gene
            gene_df <- c_df[c_df[['junction']] == gene,]
            # Calculate the following metrics
            # - sample_cells: the number of cells per sample
            # - junction_counts: the number of junctions detected for each exon type
            # - junction_cells: the number of cells with junction detection
            # - percell_junctions: the number of junctions detected per cell
            # - percent_detection: the percentage of cells with junction detection
            stat_df <- gene_df %>%
                group_by_at(vars(disease_col, sample_col, 'exon_type')) %>%
                summarize(sample_cells=n(), junction_counts=sum(counts)) %>%
                left_join(gene_df %>%
                    split(gene_df$exon_type) %>%
                    map_df(~.x %>%
                           dplyr::filter(counts > 0) %>% 
                           group_by_at(vars(disease_col, sample_col, 'exon_type')) %>% 
                           summarize(junction_cells=n())),
                    by=c(disease_col, sample_col, 'exon_type')) %>%
                mutate(junction_counts=ifelse(is.na(junction_counts), 0, junction_counts),
                       junction_counts=junction_counts + pseudo_c,
                       junction_cells=ifelse(is.na(junction_cells), 0, junction_cells),
                       percell_junctions=junction_counts / sample_cells,
                       percent_detection=round(junction_cells / sample_cells * 100, 4)) %>%
                as.data.frame() %>%
                inner_join(all_meta[, c(sample_col, study_col)],
                           by=sample_col) %>%
                unique()

                # Break if any missing values are introduced
                if (any(is.na(stat_df))) {
                    stop('Missing values introduced to the plot input data frame!')
                }
            return(stat_df)
        }) %>%
        set_names(junction_genes)
    ncount_list[[celltype]][[counttype]] <- gdf_list
    }
}

```

The following table summarizes the p-values calculated using a two-tailed Wilcoxon Rank Sum test
on **`percent_detection`** comparing each disease to Control. In the preceding volcano plots,
the y-axis summarizes **`percent_detection`**, calculated per sample within each subset.

- **Summary** table (accessible via the Excel-readable files ending with `"*_summary.csv"`):
    - `exon_type`: see [annotation reference](#annotating-input-junctions)
    - `subset_samples`: number of samples per disease condition per cell subtype
    - `subset_cells`: number of cells (barcodes) per disease condition per cell subtype
    - `MEAN/MEAN_junction_counts`: average/median number of junctions detected for the `exon_type` 
      per disease condition per sample
    - `MEAN/MEDIAN_junction_cells`: average/median number of cells with junction detection 
      associated with the `exon_type` per disease condition per sample
    - `MEAN/MEDIAN_percell_junctions`: average/median number of per-cell junctions corresponding to
      the `exon_type` per disease condition per sample
    - `MEAN/MEDIAN_percent_detection`: average/median junction detection rate 
      corresponding to the `exon_type` per disease condition per sample

- **Full** table (accessible via the Excel-readable files ending with `"*_full.csv"`):
    - `sample_cells`: number of cells (barcodes) per sample
    - `junction_counts`: number of junctions detected for the `exon_type` per sample
    - `junction_cells`: number of cells with junction detection corresponding to the `exon_type` 
      per sample
    - `percell_junctions`: number of junctions detected for the `exon_type` per cell
    - `percent_detection`: percentage of cells with junction detection associated 
      with the `exon_type` per sample

Note that a pseudo-count is added to all values to avoid division errors. The pseudo-count
is defined as the minimum value among all non-zero entries across all cells, within the raw-
or normalized scale, in the current dataset.


```{r ncell_violin, results='asis'}

# --------------------------------------------------------------------------------
# This chunk presents the expression of genes with and without junctions for CE and non-CE
# --------------------------------------------------------------------------------

disease_contrasts <- c('AD', 'Control', 'FTD')
for (celltype in names(ncount_list)) {
    cat('\n\n##', celltype, '{.tabset}\n\n')
    for (counttype in names(ncount_list[[celltype]])) {
        cat('\n\n###', counttype, '{.tabset}\n\n')
        for (gene in names(ncount_list[[celltype]][[counttype]])) {

            cat('\n\n####', paste0('CE: ', gene), '\n\n')
            # Extract subset- and gene-wise data frame
            input_df <- ncount_list[[celltype]][[counttype]][[gene]]

            # Save the full table
            name <- paste(c(celltype, counttype, gene), collapse="_")
            csv_full <- file.path(out_dir, paste0(name, "_full.csv"))
            write.csv(input_df, csv_full, row.names=FALSE, quote=FALSE)

            # Plot
            cat('\n\n##### Plot\n\n')
            p <- ggplot(input_df,
                        aes_string(x=disease_col,
                                   y="percent_detection",
                                   fill=disease_col)) +
                geom_violin(trim=TRUE) +
                theme_bw() +
                geom_quasirandom(
                    data=input_df,
                    aes_string(x=disease_col, y="percent_detection", color=study_col),
                    width=0.2) +
                stat_summary(fun="median",
                     geom="crossbar",
                     width=0.1,
                     color="black") +
                ylab('% Cells with Junction Detection') +
                facet_wrap(~exon_type) +
                theme(axis.title.x=element_blank(),
                axis.text.x=element_text(angle=90, vjust=0.5, hjust=1)) +
                scale_fill_manual(values=color_map[[disease_col]]) +
                scale_color_manual(values=color_map[[study_col]]) 

            print(p)
            cat('\n\n')

            df_list <- split(input_df, input_df$exon_type) %>%
                mclapply(function(i_df) {

                    # Count the number of samples per disease condition
                    nsample <- i_df %>%
                        unique() %>%
                        group_by_at(vars(disease_col)) %>%
                        summarize(subset_samples=n(), subset_cells=sum(sample_cells)) %>%
                        # Add the mean and median percentage of junction detection rate
                        left_join(i_df %>%
                            group_by_at(vars(disease_col)) %>%
                            summarize(
                                MEAN_junction_counts=round(mean(junction_counts), 4),
                                MEDIAN_junction_counts=round(median(junction_counts), 4),
                                MEAN_junction_cells=round(mean(junction_cells), 4),
                                MEDIAN_junction_cells=round(median(junction_cells), 4),
                                MEAN_percell_junctions=round(mean(percell_junctions), 4),
                                MEDIAN_percell_junctions=round(median(percell_junctions), 4),
                                MEAN_percent_detection=round(mean(percent_detection), 4),
                                MEDIAN_percent_detection=round(median(percent_detection), 4)),
                            by=disease_col) %>%
                        unique() %>%
                        column_to_rownames(disease_col)

                    # Calculate p-values
                    disease_pvals <- map_dbl(disease_contrasts, function(d) {
                        res <- wilcox.test(
                            x=i_df[i_df[[disease_col]] == d, 'percent_detection'],
                            y=i_df[i_df[[disease_col]] == 'Control', 'percent_detection'])
                        return(res$p.value)
                        }) %>%
                        formatC(format="e", digits=4) %>%
                        set_names(disease_contrasts)

                    # Incorporate the number of samples and p-values into a data frame and print
                    res_df <- data.frame(
                        disease=names(disease_pvals),
                        vsControl_pvalue=disease_pvals)

                    # Add calculated metrics to the result data frame
                    for (met_i in colnames(nsample)) {
                        res_df[[met_i]] <- nsample[res_df$disease, met_i]
                    }
                    return(res_df)
                    })

            # Merge data from both junction types
            stat_df <- map(names(df_list), ~df_list[[.x]] %>% mutate(exon_type=.x)) %>%
                bind_rows() %>%
                remove_rownames()

            cat('\n\n##### Summary table\n\n')
            print(knitr::kable(stat_df))
            cat('\n\n')
            csv_summary <- file.path(out_dir, paste0(name, "_summary.csv"))
            write.csv(stat_df, csv_summary, row.names=FALSE, quote=FALSE)
            link_table(csv_summary)
            link_table(csv_full)
        }
    }
}

```

P-values are shown as `NaN` if the number of samples with a percentage greater than 0 is 
too small to run statistical testing.

# Saving pseudobulk count matrices

Pseudobulk junction count matrices are saved in the following location:

```{r save_aggr_matrices}

# --------------------------------------------------------------------------------
# This chunk saves single-cell and pseudobulk count matrices for further analysis
# --------------------------------------------------------------------------------

rds <- list(sc=sc_list,
            bulk=sp_list,
            meta=do.call("rbind",
                         lapply(py$subadata_dic,
                                function(o) as.data.frame(o[['obs']]) %>%
                                    rownames_to_column('barcodes')))
            )
rds_path <- file.path(out_dir, "aggr_matrices.rds")
saveRDS(rds, rds_path)

print(rds_path)
```

# Session info

```{r session_info, collapse=FALSE}
sessionInfo()
```



