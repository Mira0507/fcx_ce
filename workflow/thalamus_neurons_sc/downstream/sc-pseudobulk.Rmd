---
title: "Pseudobulk differential analysis on cryptic exons (CEs)"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        toc: true
        toc_float: true
        toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to conduct pseudobulk differential analysis
using [DESeq2](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8) 
incorporating [zinbwave](https://link.springer.com/article/10.1186/s13059-018-1406-4). 
Zinbwave is used to downweight zeros when fitting negative binomial (NB) models to zero-inflated datasets.

Refer to the following resources for technical details:

- [DESeq2 Documentation](https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html)
- [DESeq2 GitHub](https://github.com/thelovelab/DESeq2)
- [zinbwave-deseq2 workflow](https://github.com/mikelove/zinbwave-deseq2/blob/master/zinbwave-deseq2.Rmd)

```{r libraries}
# Libraries
library(tidyverse)
library(DESeq2)
library(ggplot2)
library(parallel)
library(BiocParallel)
library(yaml)
library(RColorBrewer)
library(plotly)
library(parallel)
library(rtracklayer)
library(GenomicRanges)
library(GenomicFeatures)
library(zinbwave)
library(scran)

# Additional options
set.seed(2570)
source('../config/helpers.R')

# Specify the number of available cores
n_cores <- future::availableCores()
options(mc.cores=n_cores)
```

```{r config}

# --------------------------------------------------------------------------------
# This chunk specifies input paths and variables in R
# --------------------------------------------------------------------------------

# Path to input matrices
in_rds <- "sc-exploratory/aggr_matrices.rds"

# Path to Snakemake config
snakemake_config <- "../config/config.yaml"

# Paths to yaml config
config_yaml <- read_yaml(snakemake_config)

# Path to output directory
out_dir <- "sc-pseudobulk"

# Path to GTF
gtf_path <- "../../../input/thalamus_excitatory/genes.gtf.gz"

# Create directories if missing
for (p in c(out_dir)) {
    if (! dir.exists(p)) { dir.create(p, recursive=TRUE) }
}

# Specify a pseudocount to be added to count matrices
# NOTE: The sparsity of single cell matrix sometimes causes an error
#       that cannot calculate geometric means because of many zeros. 
#       This issue is prevented by adding a small pseudocount.
pseudocount <- 0

# Specify metadata columns for factors and factor levels
factor_groups <- list(
    general_disease=c('Control', 'FTD', 'AD'),
    renamed_annotation_cell_type_post_outlier_removal=c( 
        'ExNeu1',
        'ExNeu2',
        'SOX14_Pos_InNeu',
        'SOX14_Neg_InNeu',
        'Mixed'),
    study=c('Marsan', 'Biogen', 'Mathys'),
    study_specific_disease_specific=c(
        'Control-Marsan',
        'Control-Biogen',
        'Control-Mathys',
        'FTD-Marsan',
        'FTD-Biogen',
        'AD-Mathys')
)

# Specify HEX color code
color_map <- list(
    general_disease=c(
        # `Control-FTD`="#9999FF",
        # `Control-AD`="#6666FF",
        Control="#6666FF",
        FTD="#669900",
        AD="#FF6600"),
    study=c(
        Marsan="#FF00FF",
        Biogen="#00FFFF",
        Mathys="#BFBFBF"),
    cell_type=c(
        Astrocyte="#ABD158",
        BVC="#74858C",
        CP="#D5C18E",
        ExNeu1="#90C6E2",
        ExNeu2="#547CB2",
        InNeu1="#21409A",
        InNeu2="#262262",
        Lymphocyte="#68151F",
        Microglia="#D24A75",
        OL="#FDB515",
        OPC="#ED7020",
        PVM="#231F20")
)

# Specify column names to subset barcodes
# NOTE: Set to NULL if unnecessary
subset_col <- 'study_celltype'
sample_col <- 'SampleID_celltype'
celltype_col <- 'renamed_annotation_cell_type_post_outlier_removal'
disease_col <- "general_disease"
study_col <- 'study'

# Specify DE thresholds
lfc_thresh <- 0
alpha <- 0.1

# Specify CE target genes
ce_targets <- config_yaml[['genes']]

# TRUE or FALSE if the dispersion function needs to be replaced after inspection
replace_dispersion_function <- FALSE
```

Loading input data {.tabset}

The number of splicing junctions was counted based on cellranger-aligned reads mapped to the following
genes:

```{r genes_tested}
print(ce_targets)
```

Raw junction counts were compiled into a junction-by-barcode matrix for differential testing in the
previous analysis, [`sc-exploratory.html`](sc-exploratory.html). This matrix was preprocessed
to aggregate the counts per sample per celltype, along with their associated metadata table.
These preprocessed matrices and metadata are imported from the following location:

```{r infile_info}
print(in_rds)
```

```{r import_adata}

# --------------------------------------------------------------------------------
# This chunk imports input data saved in the previous single-cell 
# exploratory analysis. Manually edit the following code if necessary.
# --------------------------------------------------------------------------------

# Import input RDS file
obj <- readRDS(in_rds)

# Extract raw count matrices for subsets of interest
mat_list <-  map(obj[['bulk']], ~.x[['raw']])
mat_list <- mat_list[str_detect(names(mat_list), "all")]

# Extract the entire sampletable (Edit manually if necessary)
sampletable <- obj[['meta']] %>%
    remove_rownames() %>%
    mutate(SampleID_celltype=paste0(SampleID, "_", cell_type), 
           study_disease_specific_celltype=paste0(study_specific_disease_specific,
                                                  "_",
                                                  cell_type))

# Ensure to have correct levels for each factor columns
for (f in names(factor_groups)) {
    sampletable[[f]] <- factor(sampletable[[f]], levels=factor_groups[[f]])
    # Break if any of the conversion introduced missing values
    if (any(is.na(sampletable[[f]]))) {
        stop(paste0("NAs introduced to the following column:", f))
    }
}

# Prep a list of metadata tables for each subset
coldata_list <- lapply(mat_list, function(m) { 
    # Splice the metadata table based on samples in the matrix
    cdata <- sampletable[sampletable[[sample_col]] %in% colnames(m),
                         c(sample_col, names(factor_groups))] %>%
        unique()
    # Break if columns of the matrix and rows of the metadata don't match
    if (nrow(cdata) != ncol(m)) {
        stop("Rownames of coldata and colnames of matrix should be the same!")
    }
    # Reorder rows of the subsetted metadata table
    rownames(cdata) <- cdata[[sample_col]]
    cdata <- cdata[colnames(m),]
    return(cdata)
})

# Add contrasts by celltype and disease
new_subsets <- c('ExNeu1_FTD', 'ExNeu2_FTD', 'ExNeu1_AD', 'ExNeu2_AD')

for (name in new_subsets) {
    # Specify celltype and disease conditions
    subset_i <- str_split(name, '_')[[1]]

    # Subset metadata and add to the `coldata_list`
    cdata <- sampletable[sampletable[[celltype_col]] == subset_i[1] &
                         sampletable[[disease_col]] %in% c("Control", subset_i[2]),
                         c(sample_col, names(factor_groups))] %>%
        unique()

    # Subset the count matrix
    m <- mat_list[['all']]
    samples_i <- cdata[[sample_col]]
    m <- m[, samples_i]

    # Break if columns of the matrix and rows of the metadata don't match
    if (nrow(cdata) != ncol(m)) {
        stop("Rownames of coldata and colnames of matrix should be the same!")
    }

    # Reorder rows of the subsetted metadata table
    rownames(cdata) <- samples_i
    cdata <- cdata[colnames(m),]
    coldata_list[[name]] <- cdata
    mat_list[[name]] <- m
}

```

# Subsets {.tabset}

The subset-wise aggregation was performed as summarized below:

```{r subset_overview, results='asis'}

# --------------------------------------------------------------------------------
# This chunk explores the number of samples and metadata info across the subsets
# --------------------------------------------------------------------------------

# Function to summarize the number of samples (N)
summarize_N <- function(meta_df) {

    # Count the number of samples
    n_df <- meta_df %>%
        group_by_at(vars(subset_col, disease_col)) %>%
        summarize(N=n()) %>%
        spread(disease_col, N)
    # Reorder columns
    disease_order <- factor_groups[[disease_col]][factor_groups[[disease_col]] %in% 
                                                  colnames(n_df)]
    n_df <- n_df[, c(subset_col, disease_order)]
    # Replace missing values with zero
    n_df[is.na(n_df)] <- 0
    # Add a new column for all N
    n_df[['all_N']] <- rowSums(n_df[, colnames(n_df)[-1]])

    return(n_df)
}

for (name in names(coldata_list)) {

    df <- coldata_list[[name]] %>%
        remove_rownames()
    cat("##", name, "{.tabset}\n\n")
    cat("### N\n\n")
    # Prep the summary table for N
    n_df <- summarize_N(df)

    # Print tables
    print(knitr::kable(n_df))
    cat('\n\n')

    cat("### Full table\n\n")
    subchunkify(paste0(name, "_subset_N_unfiltered"))
    csv_path <- file.path(out_dir,
                          paste0(name, '_unfiltered_sampletable.csv'))
    write.csv(df,
              csv_path,
              row.names=FALSE,
              quote=FALSE)

    link_table(csv_path)
    cat('\n\n')
}
```

# Pre-filtering nonzero samples {.tabset}

Samples with zero junction counts are removed from each subset. The number of samples before
and after filtering is summarized below.


```{r prefilter_samples, results='asis'}

# --------------------------------------------------------------------------------
# This chunk filters nonzero-count samples
# --------------------------------------------------------------------------------

for (name in names(mat_list)) {
    cat("##", name, "{.tabset}\n\n")
    # Remove zero-count samples from the count matrix
    m <- mat_list[[name]]
    nonzero_samples <- colSums(m) > 0
    m <- m[, nonzero_samples]
    mat_list[[name]] <- m
    # Remove zero-count samples from the metadata table
    cdata_old <- coldata_list[[name]]
    cdata_new <- cdata_old[colnames(m),]
    coldata_list[[name]] <- cdata_new
    
    cat("### N\n\n")
    n_df <- summarize_N(cdata_new)
    cat("A total of",
        sum(!nonzero_samples),
        "samples are removed from the current subset.",
        "Refer to the following table for remaining samples:")
    print(knitr::kable(n_df))
    cat("\n\n")

    cat("### Full table\n\n")
    subchunkify(paste0(name, "_subset_N_filtered"))
    csv_path <- file.path(out_dir,
                          paste0(name, '_filtered_sampletable.csv'))
    write.csv(df,
              csv_path,
              row.names=FALSE,
              quote=FALSE)

    link_table(csv_path)
    cat('\n\n')
}

```

```{r setup_dds, cache=TRUE}

# --------------------------------------------------------------------------------
# This chunk creates dds objects per subset by modeling zero counts with zinbwave
# (https://github.com/mikelove/zinbwave-deseq2/blob/master/zinbwave-deseq2.Rmd)
# --------------------------------------------------------------------------------

# Convert the count matrix into the SummarizedExperiment obj across the subsets
# NOTE: Features that were undetected in any of the samples are removed here.
#       This is required by zinbwave
se_list <- map(mat_list, ~.x[rowSums(.x) > 0,]) %>% 
    map2(coldata_list,
         ~SummarizedExperiment(assays=list(counts=.x), colData=.y))

# Specify a design formula
design_formula <- as.formula(paste("~", disease_col))

# Model zero components
zinb_list <- mclapply(se_list, function(se) {
    nms <- c("counts", setdiff(assayNames(se), "counts"))
    assays(se) <- assays(se)[nms]
    assay(se) <- as.matrix(assay(se))
    zinbwave(Y=se,
             X=design_formula,
             K=0,
             verbose=TRUE,
             observationalWeight=TRUE,
             epsilon=1e12)

    })

# Build a list of dds objects
dds_list <- lapply(zinb_list,
                   DESeqDataSet,
                   design=design_formula) %>%
    # Estimate size factors
    mclapply(estimateSizeFactors, type="poscounts")

# Calculate Scran's sum factors
# NOTE: "Sum factors" are more robust to zeros. This method sums counts across the samples 
#        to eliminate the zeros technically, allowing it to utilize a much larger portion
#        of the features to calculate the scaling factor. In contrast, the size factors
#        estimated by the `estimateSizeFactors` function from DESeq2 relies on
#        geometric mean. This value becomes zero if a sample has a count of zero 
#        for any feature.
scr_list <- map(dds_list, computeSumFactors)

# Replace size factors with Scran's sum factors
dds_list <- mclapply(
    names(dds_list),
    function(name) {
        sizeFactors(dds_list[[name]]) <- sizeFactors(scr_list[[name]])
        dds_list[[name]] }) %>% 
    # Run DESeq
    # NOTE: Set the `fitType` argument to "mean" only if none of the options work
    lapply(function(dds)
        DESeq(dds,
              test="LRT",
              reduced=~1,
              minmu=1e-6,
              minRep=Inf,
              parallel=TRUE,
              fitType="mean")
    ) %>%
    set_names(names(scr_list))

# Run log2(normalized_counts + 1) transformation
# NOTE: The current dataset cannot use the `varianceStabilizingTransformation` nor `vst` function as 
#       the gene-wise dispersions are almost constant over the mean, so DESeq2 cannot fit 
#       its usual mean–dispersion curve (“parametric”, “local”, or “mean”).
l2t_list <- lapply(names(dds_list), function(name) {
    dds <- dds_list[[name]]
    # varianceStabilizingTransformation(dds, blind=TRUE)
    m <- log2(counts(dds, normalized=TRUE) + 1)
    return(m)
}) %>%
set_names(names(dds_list))
```

# Quality control (QC)

## Sample similarity heatmap {.tabset}

Sample-to-sample similarity in junction profiling is explored using a heatmap of normalized counts 
(log2 scale), with *Euclidean distance* represented by the color scale. Darker blue indicates
less distance (i.e., greater similarity) in splice junction profiling. Note that this analysis 
excluded junctions that were not detected in any of the samples.

```{r qc_heatmap, results='asis', fig.height=8, fig.width=8}

# --------------------------------------------------------------------------------
# This chunk explores sample similarity using heatmap
# --------------------------------------------------------------------------------

for (name in names(l2t_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Prep a matrix
    scmat <- l2t_list[[name]] %>%
        t() %>%
        dist() %>%
        as.matrix()

    # Set color to be displayed
    colors <- colorRampPalette(rev(RColorBrewer::brewer.pal(9, 'Blues')))(255)

    # Prep metadata for heatmap
    h_meta <- coldata_list[[name]]
    h_meta <- h_meta[, c(disease_col, subset_col)]
    h_meta <- h_meta[, colnames(h_meta) != sample_col]

    # Print heatmap
    print(pheatmap::pheatmap(
        scmat,
        scale='none',
        color=colors,
        annotation_col=h_meta,
        annotation_colors=color_map,
        show_rownames=FALSE,
        show_colnames=FALSE,
        cluster_cols=TRUE,
        border_color=NA
    )
    )
    cat('\n\n')
}

```

## PCA {.tabset}

Another way of looking at sample clustering is principal components analysis (PCA). Each axis does
not have units, rather, it represents the dimensions along which the samples vary the most. The amount 
of variance explained by each principal component is indicated in the axes label. Note that this analysis 
excluded junctions that were not detected in any of the samples.

```{r qc_pca, results='asis'}

# --------------------------------------------------------------------------------
# This chunk explores sample similarity using PCA
# --------------------------------------------------------------------------------

for (name in names(l2t_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Prep a matrix
    scmat <- l2t_list[[name]] %>%
        t()

    # Prep metadata
    p_meta <- coldata_list[[name]]

    # Run PCA
    pca <- prcomp(scmat, center=TRUE, scale=FALSE)
    # Calculate variance explained by each PC
    var_exp <- round(pca$sdev^2/sum(pca$sdev^2) * 100, 2)

    # Prep input dataframe for plotting
    df <- pca$x[,1:2] %>%
        as.data.frame() %>%
        rownames_to_column(sample_col) %>%
        left_join(p_meta, by=sample_col)
    # Prep titles for axes
    axis_titles <- map_chr(
        1:2,
        ~paste0("PC ", .x, " (", var_exp[.x], "%)")
    )

    # Plot PCA
    condition_cols <- colnames(p_meta)[-1] %>%
        sapply(function(c) length(unique(p_meta[[c]])) > 1)
    condition_cols <- colnames(p_meta)[-1][condition_cols]
    for (c in condition_cols) {
        cat('####', c, '\n\n')
        p <- ggplot(df,
                    aes_string(x='PC1',
                               y='PC2',
                               color=c,
                               shape=celltype_col)) +
            geom_point(alpha=0.7, size=3) +
            theme_bw() +
            xlab(axis_titles[1]) +
            ylab(axis_titles[2])
        # Add color code if available
        if (c %in% names(color_map)) {
            p <- p + scale_color_manual(values=color_map[[c]])
        }
        print(p)
        cat('\n\n')
    }
}

```

## Size factors {.tabset}

Ideally, all libraries were sequenced to identical depth, in which case all size factors would be 1.0. 
In practice, this is almost never the case due to the difficulties of accurately measuring 
low concentrations of cDNA. DESeq2 uses size factor estimates to normalized for sequencing depth across 
libraries. If some libraries are much higher or lower than 1 then those libraries had dramatically
different coverage and we should be careful about interpreting results.


Unlike the standard DESeq2 workflow, which uses the median-of-ratio method, the current analysis
estimates size factors using the [deconvolution method](https://doi.org/10.1186/s13059-016-0947-7).
This method is robust to many zeros by pooling counts across samples during size factor estimation,
whereas the median-of-ratio method relies on geometric means, which returns zero if any feature
has a count of zero.

These diagnostic plots show the size factors (as a ranked bar plot) and the relationship between the size 
factors and the total read count (as a scatterplot). Samples whose total read count differs from size
factor may indicate that the sample has a small number of highly expressed features.

```{r size_factors, results='asis'}

# --------------------------------------------------------------------------------
# This chunk explores size factors across the samples
# --------------------------------------------------------------------------------

for (name in names(dds_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Extract and reorder size factors
    dds <- dds_list[[name]]
    sf <- sizeFactors(dds)
    sf <- sf[order(sf)] %>%
        tibble::enframe(value="Size Factor")

    p <- ggplot(sf) +
        aes(x=reorder(name, `Size Factor`), y=`Size Factor`) +
        xlab('cluster') +
        geom_col() +
        theme_bw() +
        theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1))

    cat('#### Size factors\n\n')
    subchunkify(paste(name, '_sizefactor1'), input='plot', width=10)
    cat('\n\n')

    trc <- colSums(counts(dds)) %>% 
        tibble::enframe(value = 'Total Read Count')
    trc_vs_sf <- dplyr::full_join(sf, trc, by='name')
    p <- ggplot(data=trc_vs_sf,
                aes_string(x="`Total Read Count`", y="`Size Factor`", label='name')) +
        geom_point(size=3) +
        theme_bw() +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

    cat('#### Size factors vs total read counts\n\n')
    subchunkify(paste(name, '_sizefactor2'), input='plot')
    cat('\n\n')
}

```

## Dispersion {.tabset}

The DESeq2 dispersion estimates are inversely related to the mean and directly related to variance.
Based on this relationship, the dispersion is higher for small mean counts and lower for large 
mean counts. Therefore, the dispersion estimates reflect the variance in gene expression for a given 
mean value. 

Due to the zero-inflated nature of the input dataset, we estimate gene-wise dispersions both including
and excluding low-count features. Feature filtering is not carried forward to the differential testing step
once dispersion estimation is complete. After a thorough inspection, decide whether to replace the current
dispersion function with an updated one calculated based on the filtered data.

Note that the dispersion estimation performed here follows the DESeq2 workflow that incorporates zinbwave, 
which is designed to better handle zero-inflated data. See the following page for more information:
[zinbwave-deseq2-dispersion](https://github.com/mikelove/zinbwave-deseq2/blob/master/zinbwave-deseq2.Rmd#L117)


```{r replace_dispersion_function}
if (replace_dispersion_function) {
    print("Dispersion functions replaced with re-captured ones!")
} else {
    print("Dispersion functions are taken from raw dispersion!")
}
```

```{r dispersion, results='asis'}

# --------------------------------------------------------------------------------
# This chunk explores dispersions across the features
# Dispersion functions are replaced if necessary
# --------------------------------------------------------------------------------

for (name in names(dds_list)) {
    cat("\n\n###", name, "{.tabset}\n\n")
    dds <- dds_list[[name]]

    cat("\n\n#### Raw dispersion\n\n")
    # Inspect the current dispersion-mean relationship as-is
    plotDispEsts(dds)

    # Recapture dispersion-mean relationship after further filtering features 
    # above the threshold. This threshold is determined empirically.
    cat("\n\n#### Re-captured dispersion\n\n")
    keepForDispTrend <- rowSums(counts(dds, normalized=TRUE) >= 0.5) >= 1
    dds2 <- dds[keepForDispTrend,]
    dds2 <- estimateDispersionsFit(dds2, fitType='mean')
    dds2 <- estimateDispersionsMAP(dds2)
    # Inspect the updated dispersion-mean relationship
    plotDispEsts(dds2)
    cat("\n\n")

    # Replace the dispersion function if necessary
    if (replace_dispersion_function) {
        dispersionFunction(dds) <- dispersionFunction(dds2)
        dds <- estimateDispersionsMAP(dds)
        # dds_list[[name]] <- nbinomLRT(dds, reduced=~1, minmu=1e-6)
        dds_list[[name]] <- nbinomWaldTest(dds)
    }
}
```

# Differential testing {.tabset}

We perform pairwise differential testing using the [Wald test](https://en.wikipedia.org/wiki/Wald_test);
therefore, subsets containing more than one disease status are not examined.


## Summary table

- **subset**: study and celltype
- **nonzero.vs.total**: the number of junctions with nonzero read counts and the total number of 
  tested junctions
- **alpha**: false discovery rate (FDR) cutoff determining significant genes
- **lfcThreshold**: by default, the null hypothesis is that the log2 fold change of splicing is 
  not different from zero. In some circumstances, it is useful to use a different threshold, 
  which will be reported here.
- **outliers**: Cook’s distance is used as a measure of how much a single sample is influencing 
  the fitted coefficients for a junction. If that value is too high, the gene is marked as an 
  outlier and the pvalue and adjusted pvalue will be set to NA. If there are many 
  (hundreds to thousands) of outliers, this is an indication that a sample may be problematic. 
  In this case, the dds diagnostics plots may help identify the culprit.
- **low.counts**: How many junctions were not even tested for differential analysis because they 
  had too low counts.
- **test**: The contrast performed using the design. `A vs B` indicates differential expression of junctions
  in A (experimental) compared to B (control).


```{r de_summary, results='asis'}

# --------------------------------------------------------------------------------
# This chunk summarizes testing results
# --------------------------------------------------------------------------------

# Calculate results
res_list <- mclapply(dds_list[!str_detect(names(dds_list), "all")], results)

lapply(names(res_list), function(name) {
    # Extract res and dds objects
    res <- res_list[[name]]
    dds <- dds_list[[name]]
    # Summary metrics
    notallzero <- sum(res$baseMean > 0)
    up <- sum(res$padj < alpha & res$log2FoldChange > lfc_thresh, na.rm=TRUE)
    down <- sum(res$padj < alpha & res$log2FoldChange < -lfc_thresh, na.rm=TRUE)
    filt <- sum(!is.na(res$pvalue) & is.na(res$padj))
    outlier <- sum(res$baseMean > 0 & is.na(res$pvalue))
    test <- mcols(res)['log2FoldChange', 'description']

    # Build a summary dataframe
    data.frame(
        subset=name,
        up=up,
        down=down,
        nonzero.vs.total=paste0(notallzero, '/', nrow(res)), 
        alpha=alpha,
        lfcThreshold=lfc_thresh,
        outliers=outlier,
        low.counts=filt,
        # adjust width.cutoff here because newline insertion causes this to return
        # a df with multiple duplicate rows
        design=deparse(design(dds), width.cutoff=500L),
        test=test
    )
}) %>%
bind_rows() %>%
knitr::kable()
```

## Full table {.tabset}

Metrics:

- **chr**, **start**, **end**: junction genomic coordinates
- **gene_name**: gene name corresponding to the splice junction
- **baseMean**: mean normalized counts of the splice junction in all samples
- **log2FoldChange**: fold changes in a log2 scale
- **lfcSE**: standard error of the log2 fold change. A smaller value suggests a more precise estimate of 
  the fold change.
- **stat**: test statistic. For the Wald test, this metric refers to the log2FoldChange divided by lfcSE,
  which is compared to a standard normal distribution to generate a two-tailed pvalue. For the likelihood
  ratio test (LRT), stat is the difference in deviance between the reduced model and the full model, which 
  is compared to a chi-squared distribution to generate a pvalue.
- **pvalue**: raw p-values
- **padj**: false discovery rate (FDR) computed using the Benjamini-Hochberg (BH) method
- **exon_type**:
    - *cryptic*: one or both of the start and end coordinates of the junction is within intron regions
    - *non-cryptic-annotated*: both the start and end of the junction coordinates are at annotated positions
    - *non-cryptic-novel*: neither coordinate of the junction is within an intron AND either position 
      is at non-annotated positions

It's assumed that only the *cryptic* type generates CEs by starting or ending at an intron.

```{r de_full, results='asis'}

# --------------------------------------------------------------------------------
# This chunk displays full results
# --------------------------------------------------------------------------------

for (name in names(res_list)) {
    cat('###', name, '\n\n')
    # Clean the result data frame
    df <- res_list[[name]] %>%
        as.data.frame() %>%
        rownames_to_column('exon_type') %>%
        separate(exon_type,
                 c('chr', 'start', 'end', 'gene_name', 'exon_type'),
                 sep=":") %>%
        mutate(exon_detection=ifelse(exon_type == "cryptic",
                                     "CE detected",
                                     "junction detected without CE")) %>%
        remove_rownames()

    # Print
    print(knitr::kable(df))
    cat('\n\n')

    # Save
    csv_path <- file.path(out_dir,
                          paste0(name, '_differential_results.csv'))
    write.csv(df, csv_path, row.names=FALSE, quote=FALSE)
    link_table(csv_path)
    cat('\n\n')
}
```

# Distribution of junction counts {.tabset}

Log-normalized pseudobulk counts are compared across disease conditions. Junctions 
with zero counts across all samples are excluded. 

The distribution is shown using a violin plot alongside a scatter plot, where each point 
represents a sample and is colored by study. The black horizontal line indicates the
median of each distribution.

```{r prep_counting}

# --------------------------------------------------------------------------------
# This chunk preps input data frames for plotting
# --------------------------------------------------------------------------------

norm_list <- mclapply(names(mat_list), function(name) {

    # Extract the raw count matrix corresponding to the current subset
    m <- mat_list[[name]]

    # Transform the matrix to a natural log scale and clean data frame
    df <- log1p(m) %>%
        as.data.frame() %>%
        rownames_to_column('junction') %>%
        pivot_longer(!junction,
                     names_to=sample_col,
                     values_to="counts") %>%
        inner_join(sampletable[, c(sample_col, names(factor_groups))],
                   by=sample_col) %>%
        unique() %>%
        as.data.frame()

    # Add a column for spliced gene names
    df[['gene_spliced']] <- map_chr(df[['junction']],
                                    ~str_split(.x, "\\:")[[1]][4])

    # Add a column for generated exons
    df[['exon_detection']] <- ifelse(str_detect(df[['junction']], "non-cryptic"),
                                     "junction detected without CE",
                                     "CE detected")

    return(df)

}) %>%
set_names(names(mat_list))

# Ensure no missing values were introduced
for (name in names(norm_list)) {
    if (any(is.na(norm_list[[name]]))) {
        stop(paste0("Missing values introduced to the following contrast in `norm_list`:",
                    name))
    }
}


```

```{r define_plot_functions}

# --------------------------------------------------------------------------------
# This chunk sets up functions to visualize the distribution of junction counts and ratios
# --------------------------------------------------------------------------------

# Specify the plot format displaying counts
count_plot <- function(input_df, dcol, scol, ylabel) {

    ggplot(input_df,
        aes_string(x=dcol, y='counts', fill=dcol)) +
        geom_violin(trim=FALSE) +
        theme_bw() +
        geom_point(data=input_df,
           aes_string(x=dcol, y='counts', color=scol)) +
        stat_summary(fun="median",
             geom="crossbar",
             width=0.1,
             color="black") +
        ylab('log-normalized junction counts') +
        theme(axis.title.x=element_blank(),
        axis.text.x=element_text(angle=90, vjust=0.5, hjust=1)) +
        scale_fill_manual(values=color_map[[dcol]]) +
        scale_color_manual(values=color_map[[scol]])
}

# Specify the plot format displaying ratios
ratio_plot <- function(input_df, dcol, scol, ylabel) {

    ggplot(input_df, aes_string(x=dcol, y='ratio', fill=dcol)) +
           geom_violin(trim=FALSE) +
           geom_point(data=input_df,
                      aes_string(x=dcol, y='ratio', color=scol)) +
           stat_summary(fun="median",
                        geom="crossbar",
                        width=0.1,
                        color="black") +
           theme_bw() +
           ylab(ylabel) +
           theme(axis.title.x=element_blank(),
                 axis.text.x=element_text(angle=90, vjust=0.5, hjust=1)) +
           scale_fill_manual(values=color_map[[dcol]]) +
           scale_color_manual(values=color_map[[scol]]) +
           scale_y_log10()
    }
```



## Counts for splice junctions {.tabset}

Log-normalized pseudobulk counts are compared across the disease conditions. Junctions 
with zero counts across all samples are excluded.

```{r junction_count_dist, results='asis', fig.width=10}

# --------------------------------------------------------------------------------
# This chunk displays individual junction counts across all disease conditions
# --------------------------------------------------------------------------------

condition_reorder <- c('AD', 'Control', 'FTD')

for (name in names(norm_list)) {
    cat('\n\n###', name, '{.tabset}\n\n')
    df <- norm_list[[name]]
    for (ce in ce_targets) {
        cat('\n\n####', ce, '\n\n')
        # Subset rows for the corresponding CE target gene
        ce_df <- df[str_detect(df$junction, ce), ]
        ce_df[[disease_col]] <- factor(ce_df[[disease_col]],
                                       levels=condition_reorder)

        if (nrow(ce_df) > 0) {

            p <- count_plot(input_df=ce_df,
                            dcol=disease_col,
                            scol=study_col,
                            ylabel='log-normalized junction conts') +
                facet_wrap(. ~ junction,
                           scales="free_y")

            print(p)
        } else {
            cat("\n\nCount not displayed!\n\n")
        }
    }
}
```

## Counts for CEs {.tabset}

Log-normalized counts are aggregated on whether it results in CE generation.


```{r ce_count_dist, results='asis'}

# --------------------------------------------------------------------------------
# This chunk displays CE or non-CE junction counts across all disease conditions
# --------------------------------------------------------------------------------

for (name in names(norm_list)) {
    cat('\n\n###', name, '{.tabset}\n\n')
    df <- norm_list[[name]]

    for (ce in ce_targets) {
        cat('\n\n####', ce, '\n\n')
        # Subset rows for the corresponding CE target gene
        ce_df <- df[str_detect(df$junction, ce), ] %>%
            group_by_at(vars(sample_col,
                             "exon_detection",
                             disease_col,
                             study_col)) %>%
            summarize(counts=sum(counts))
        ce_df[[disease_col]] <- factor(ce_df[[disease_col]],
                                       levels=condition_reorder)

        if (nrow(ce_df) > 0) {

            # Plot
            p <- count_plot(input_df=ce_df,
                            dcol=disease_col,
                            scol=study_col,
                            ylabel='log-normalized counts for junctions with or without CEs') +
                facet_wrap(. ~ exon_detection,
                           scales="free_y")

            print(p)
        } else {
            cat("\n\nCount not displayed!\n\n")
        }
    }
}

```

## CE/non-CE ratios {.tabset}

The counts for junctions with CEs are divided by the counts for junctions without CEs. Note that samples 
not containing any junctions are omitted. 1/10 of non-zero minimum value is added to all remaining entries 
to avoid errors when dividing values. The non-zero minimum value was calculated for each CE target 
(e.g. STMN2) within a subset (e.g. ExNeu1).



```{r ce_ratio, results='asis', fig.width=6}

# --------------------------------------------------------------------------------
# This chunk compares CE/non-CE counts across all disease conditions
# --------------------------------------------------------------------------------

for (name in names(mat_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Extract input data frame
    df <- norm_list[[name]]
    
    for (ce in ce_targets) {
        cat('####', ce, '{.tabset}\n\n')
        # Subset rows for the corresponding CE target gene
        ce_df <- df[str_detect(df$junction, ce), ] %>%
            group_by_at(vars(sample_col,
                             "exon_detection",
                             study_col,
                             disease_col)) %>%
            summarize(counts=sum(counts))
        ce_df[[disease_col]] <- factor(ce_df[[disease_col]],
                                       levels=condition_reorder)

        e_detection <- unique(ce_df$exon_detection)
        if (length(e_detection) > 1 & sum(ce_df$counts) > 0) {
            # Calculate the nonzero min value
            nonzero_min <- min(ce_df$counts[ce_df$counts > 0])

            # Prep input for a boxplot
            ce_df <- ce_df %>%
                pivot_wider(names_from=exon_detection, values_from=counts) %>%
                # Impute missing values with zero
                mutate_if(is.numeric, function(x) ifelse(is.na(x), 0, x))

            # Remove samples if they have zero counts for all exon_detection groups
            ce_df <- ce_df[rowSums(ce_df[, e_detection]) > 0,] %>%
                # Add a pseudocount of nonzero_min to all numeric entries
                mutate_if(is.numeric, function(x) x + 0.1 * nonzero_min) %>%
                # Calculate CE/non-CE counts
                mutate(ratio=`CE detected` / `junction detected without CE`,
                       metric="Ratio") %>%
                as.data.frame() %>%
                unique()

            # Plot
            p <- ratio_plot(input_df=ce_df,
                            dcol=disease_col,
                            scol=study_col,
                            ylabel='Count ratios (CE / non-CE)')
            print(p)

            cat('\n\n')

        } else {
            cat("\n\nRatio not displayed!\n\n")
        }
    }
}

```

## CE/all-junctions ratios {.tabset}

The counts for junctions with CEs are divided by the counts for all extracted junctions. Note that samples 
not containing any junctions are omitted. 1/10 of non-zero minimum value is added to all remaining entries 
to avoid errors when dividing values. The non-zero minimum value was calculated for each CE target 
(e.g. STMN2) within a subset (e.g. ExNeu1).

```{r ce_over_all, results='asis', fig.width=6}

# --------------------------------------------------------------------------------
# This chunk compares CE/all counts
# --------------------------------------------------------------------------------

for (name in names(mat_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Extract input data frame
    df <- norm_list[[name]]
    
    for (ce in ce_targets) {
        cat('####', ce, '\n\n')
        # Subset rows for the corresponding CE target gene
        ce_df <- df[str_detect(df$junction, ce), ] %>%
            group_by_at(vars(sample_col,
                             "exon_detection",
                             study_col,
                             disease_col)) %>%
            summarize(counts=sum(counts))
        ce_df[[disease_col]] <- factor(ce_df[[disease_col]],
                                       levels=condition_reorder)

        e_detection <- unique(ce_df$exon_detection)
        if (length(e_detection) > 1 & sum(ce_df$counts) > 0) {
            # Calculate the nonzero min value
            nonzero_min <- min(ce_df$counts[ce_df$counts > 0])

            # Prep input for a boxplot
            ce_df <- ce_df %>%
                pivot_wider(names_from=exon_detection, values_from=counts) %>%
                # Impute missing values with zero
                mutate_if(is.numeric, function(x) ifelse(is.na(x), 0, x)) %>%
                as.data.frame()
            # Add a column for all counts
            ce_df[["all junctions"]] <- rowSums(ce_df[, e_detection])

            # Remove samples if they have zero counts for all exon_detection groups
            ce_df <- ce_df %>%
                # Add a pseudocount of nonzero_min to all numeric entries
                mutate_if(is.numeric, function(x) x + 0.1 * nonzero_min) %>%
                # Calculate CE/non-CE counts
                mutate(ratio=`CE detected` / `all junctions`,
                       metric="Ratio") %>%
                as.data.frame() %>%
                unique()

            # Plot
            p <- ratio_plot(input_df=ce_df,
                            dcol=disease_col,
                            scol=study_col,
                            ylabel='Count ratios (CE / all-junctions)')

            print(p)
            cat('\n\n')

        } else {
            cat("\n\nRatio not displayed!\n\n")
        }

    }
}

```

# Pairwise Wilcoxon Rank Sum test {.tabset}

We perform pairwise differential tests comparing each disease group to control. Because the dataset
does not meet the normality assumption, we use a two-tailed Wilcoxon Rank Sum test (Mann-Whitney U),
followed by the BH method. CSV files containing p-values and individual counts are linked below each
result table. Note that contrasts with many zero counts can failed, returning missing values (`NaN`).


```{r prep_wilcox_test}

# --------------------------------------------------------------------------------
# This chunk sets up a pairwise t- or wilcoxon test
# --------------------------------------------------------------------------------

# Function to calculate p-values using t-test or wilcox test
calc_pval <- function(dataframe, response_col, explanatory_col, split_col, stat="ttest") {

    # Specify a design formula
    formula_str <- paste(response_col, "~", explanatory_col)
    sapply(unique(dataframe[[split_col]]), function(j) {
        df_i <- dataframe[dataframe[[split_col]] == j,]
        tryCatch(
            { 
                if (stat == "ttest") {
                    t.test(as.formula(formula_str), data=df_i)$p.value
                } else if (stat == "wilcox") {
                    wilcox.test(as.formula(formula_str), data=df_i, exact=FALSE)$p.value
                } else {
                    stop("Wrong statistics!")
                }
            },
            error = function(e) { 
                NA 
            })
        }
    )
}

# Function to subset and clean a count data frame
subset_clean_counts <- function(dataframe, disease_label) {
    dataframe[dataframe[[disease_col]] %in% c('Control', disease_label),] %>%
        group_by_at(vars(sample_col,
                         "exon_detection",
                         "gene_spliced",
                         disease_col)) %>%
        summarize(counts=sum(counts))
}

# Function to run a count division
# denom="nonce" (divide by non-CE junctions) or "all" (divide by all junctions)
calculate_ratios <- function(dataframe, denom="nonce") {

    # Prep input for a boxplot
    dataframe <- dataframe %>%
        pivot_wider(names_from=exon_detection, values_from=counts) %>%
        # Impute missing values with zero
        mutate_if(is.numeric, function(x) ifelse(is.na(x), 0, x))

    # Add a column for all counts
    dataframe[["all junctions"]] <- rowSums(dataframe[, e_detection])

    # Remove samples if they have zero counts for all exon_detection groups
    dataframe <- dataframe[rowSums(dataframe[, e_detection]) > 0,] %>%
        # Add a pseudocount of nonzero_min to all numeric entries
        mutate_if(is.numeric, function(x) x + 0.1 * nonzero_min) %>%
        as.data.frame() %>%
        unique()

    # Add a new column calculating division
    denom_col <- ifelse(denom == "nonce",
                        "junction detected without CE",
                        "all junctions")
    dataframe[['ratio']] <- dataframe[["CE detected"]] / dataframe[[denom_col]]
    # Add a new column as a placeholder in case not needing to split the data frame
    dataframe[['metric']] <- 'Ratio'

    return(dataframe)
}


# Extract disease labels to be tested in the current dataset
diseases <- factor_groups[[disease_col]]
diseases <- diseases[diseases != "Control"]
```


## Counts for splice junctions {.tabset}

```{r wilcox_junction_counts, results='asis'}

# --------------------------------------------------------------------------------
# This chunk performs a t- or wilcoxon test at on individual junction counts
# --------------------------------------------------------------------------------

for (name in names(norm_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Retrieve input
    df <- norm_list[[name]]
    for (d in diseases) {
        contr_label <- paste0(d, "_vs_Control")
        cat('####', contr_label, '\n\n')
        if (d %in% df[[disease_col]]) {
            cat('##### Comparisons\n\n')
            # Subset the input data frame 
            df_subset <- df[df[[disease_col]] %in% c('Control', d),]
            # Calculate p-values
            pval <- calc_pval(dataframe=df_subset,
                              response_col='counts',
                              explanatory_col=disease_col,
                              stat='wilcox',
                              split_col='junction')
            # Add FDR
            pval_df <- data.frame(junction=names(pval),
                                  pvalue=pval,
                                  FDR=p.adjust(pval, method="BH")) %>%
                remove_rownames()

            print(knitr::kable(pval_df))
            cat('\n\n')

            # Save the p-value table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_junction_comparisons.csv")
            write.csv(pval_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)
            cat('##### Counts\n\n')
            # Display mean and median counts for each junction
            stat_df <- split(df_subset, df_subset$junction) %>%
                map_df(function(df_i) df_i %>%
                       group_by_at(vars(disease_col, 'junction')) %>%
                       summarize(junction=junction,
                                 N=n(),
                                 average_counts=mean(counts),
                                 median_counts=median(counts)) %>%
                       unique()) %>%
                as.data.frame()
            print(knitr::kable(stat_df))
            cat('\n\n')
            # Save the stat table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_junction_counts.csv")
            write.csv(stat_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)

        } else {
            cat("\n\nContrast unavailable!\n\n")
        }
    }
}

```

## Counts for CEs {.tabset}

```{r wilcox_ce_counts, results='asis'}

# --------------------------------------------------------------------------------
# This chunk performs a t- or wilcoxon test on junction counts associated with CEs or non-CEs
# --------------------------------------------------------------------------------

for (name in names(norm_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Retrieve input
    df <- norm_list[[name]]
    for (d in diseases) {
        contr_label <- paste0(d, "_vs_Control")
        cat('####', contr_label, '\n\n')
        if (d %in% df[[disease_col]]) {
            cat('##### Comparisons\n\n')
            # Subset the input data frame 
            df_subset <- subset_clean_counts(dataframe=df, disease_label=d)

            # Calculate p-values
            pval_list <- split(df_subset, df_subset[['gene_spliced']])
            pval_df <- map(names(pval_list), function(g) {
                vec <- calc_pval(dataframe=pval_list[[g]],
                    response_col='counts',
                    explanatory_col=disease_col,
                    stat='wilcox',
                    split_col='exon_detection')
                data.frame(gene=g, junction=names(vec), pvalue=vec) }) %>%
                bind_rows() %>%
                mutate(FDR=p.adjust(pvalue, method="BH")) %>%
                remove_rownames()

            print(knitr::kable(pval_df))
            cat('\n\n')

            # Save the p-value table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_CE_comparisons.csv")
            write.csv(pval_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)

            cat('##### Counts\n\n')
            # Display mean and median counts for each junction
            stat_list <- split(df_subset, df_subset[['gene_spliced']])
            stat_df <- map(names(stat_list), ~stat_list[[.x]] %>%
                group_by_at(vars(disease_col, 'exon_detection')) %>%
                summarize(gene=.x,
                          exon_detection=exon_detection,
                          N=n(),
                          average_counts=mean(counts),
                          median_counts=median(counts)) %>%
                unique()) %>%
                bind_rows() %>%
                as.data.frame() %>%
                arrange(gene, exon_detection)
            print(knitr::kable(stat_df))
            cat('\n\n')
            # Save the stat table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_CE_counts.csv")
            write.csv(stat_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)

        } else {
            cat("\n\nContrast unavailable!\n\n")
        }
    }
}

```


## CE/non-CE ratios {.tabset}

```{r wilcox_ratios_ce_nonce, results='asis'}

# --------------------------------------------------------------------------------
# This chunk performs a t- or wilcoxon test on count ratios between CE and non-CEs
# --------------------------------------------------------------------------------

for (name in names(norm_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Retrieve input
    df <- norm_list[[name]]
    for (d in diseases) {
        contr_label <- paste0(d, "_vs_Control")
        cat('####', contr_label, '\n\n')
        if (d %in% df[[disease_col]]) {
            cat('##### Comparisons\n\n')
            # Subset the input data frame 
            df_subset <- subset_clean_counts(dataframe=df, disease_label=d)

            # Calculate p-values
            ratio_list <- split(df_subset, df_subset[['gene_spliced']])
            pval_list <- list()
            df_list <- list()
            for (gene in names(ratio_list)) {
                gene_df <- ratio_list[[gene]]
                e_detection <- unique(gene_df[['exon_detection']])
                if (length(e_detection) > 1 & sum(gene_df$counts) > 0) {
                    # Calculate the nonzero min value
                    nonzero_min <- min(gene_df$counts[gene_df$counts > 0])

                    # Add a division
                    gene_df <- calculate_ratios(dataframe=gene_df, denom="nonce")

                    pval_list[[gene]] <- calc_pval(dataframe=gene_df,
                                                   response_col="ratio",
                                                   explanatory_col=disease_col,
                                                   split_col="metric",
                                                   stat='wilcox') 
                    df_list[[gene]] <- gene_df
                }
            }
            pval_df <- data.frame(gene=names(pval_list),
                                  pvalue=unlist(pval_list),
                                  FDR=p.adjust(unlist(pval_list), method="BH")) %>%
                remove_rownames()

            print(knitr::kable(pval_df))
            cat('\n\n')

            # Save the p-value table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_CE_over_nonCE_comparisons.csv")
            write.csv(pval_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)

            cat('##### Ratios\n\n')
            # Display mean and median counts for each junction
            stat_df <- df_list %>%
                bind_rows() %>%
                mutate(gene=gene_spliced) %>%
                group_by_at(vars('gene', disease_col)) %>%
                summarize(N=n(),
                          average_ratio=mean(ratio),
                          median_ratio=median(ratio)) %>%
                unique()

            print(knitr::kable(stat_df))
            cat('\n\n')

            # Save the stat table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_CE_over_nonCE_ratios.csv")
            write.csv(stat_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)

        } else {
            cat("\n\nContrast unavailable!\n\n")
        }
    }
}

```

## CE/all-junctions ratios {.tabset}

```{r wilcox_ratios_ce_all, results='asis'}

# --------------------------------------------------------------------------------
# This chunk performs a t- or wilcoxon test on count ratios between CE and all junctions
# --------------------------------------------------------------------------------

for (name in names(norm_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Retrieve input
    df <- norm_list[[name]]
    for (d in diseases) {
        contr_label <- paste0(d, "_vs_Control")
        cat('####', contr_label, '\n\n')
        if (d %in% df[[disease_col]]) {
            cat('##### Comparisons\n\n')
            # Subset the input data frame 
            df_subset <- subset_clean_counts(dataframe=df, disease_label=d)

            # Calculate p-values
            ratio_list <- split(df_subset, df_subset[['gene_spliced']])
            pval_list <- list()
            df_list <- list()
            for (gene in names(ratio_list)) {
                gene_df <- ratio_list[[gene]]
                e_detection <- unique(gene_df[['exon_detection']])
                if (length(e_detection) > 1 & sum(gene_df$counts) > 0) {
                    # Calculate the nonzero min value
                    nonzero_min <- min(gene_df$counts[gene_df$counts > 0])

                    # Add a division
                    gene_df <- calculate_ratios(dataframe=gene_df, denom="all")

                    pval_list[[gene]] <- calc_pval(dataframe=gene_df,
                                                   response_col="ratio",
                                                   explanatory_col=disease_col,
                                                   split_col="metric",
                                                   stat='wilcox') 
                    df_list[[gene]] <- gene_df
                }
            }
            pval_df <- data.frame(gene=names(pval_list),
                                  pvalue=unlist(pval_list),
                                  FDR=p.adjust(unlist(pval_list), method="BH")) %>%
                remove_rownames()

            print(knitr::kable(pval_df))
            cat('\n\n')

            # Save the p-value table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_CE_over_all_comparisons.csv")
            write.csv(pval_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)

            cat('##### Ratios\n\n')
            # Display mean and median counts for each junction
            stat_df <- df_list %>%
                bind_rows() %>%
                mutate(gene=gene_spliced) %>%
                group_by_at(vars('gene', disease_col)) %>%
                summarize(N=n(),
                          average_ratio=mean(ratio),
                          median_ratio=median(ratio)) %>%
                unique()

            print(knitr::kable(stat_df))
            cat('\n\n')

            # Save the stat table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_CE_over_all_ratios.csv")
            write.csv(stat_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)

        } else {
            cat("\n\nContrast unavailable!\n\n")
        }
    }
}

```

# BED files {.tabset}

## Splice junctions

The following BED file contains the splice junctions tested in the current differential analysis.
Refer to the naming convention when loading the file in IGV: `<chr>:<start>:<end>:<gene_name>:<exon_type>`. 

```{r create_intron_bed, results='asis'}

# --------------------------------------------------------------------------------
# This chunk preps a BED file for tested splice junctions
# --------------------------------------------------------------------------------

# Prep coordinates and annotation in a data frame
df <- data.frame(junction=rownames(dds_list[[1]])) %>%
    separate(junction,
             c('chr', 'start', 'end', 'gene_name', 'exon_type'),
             sep=":") %>%
    unite("annotation", chr:exon_type, remove=FALSE, sep=":") %>%
    dplyr::select(chr, start, end, annotation)

# Save
bed_path <- file.path(out_dir, "junctions.bed")
write.table(df,
            file=bed_path,
            sep="\t",
            col.names=FALSE,
            row.names=FALSE,
            quote=FALSE)

link_table(bed_path)
```
 


# Session info

```{r session_info, collapse=FALSE}
sessionInfo()
```

