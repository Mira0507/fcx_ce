---
title: "Pseudobulk differential analysis on cryptic exons (CEs)"
author: "Mira Sohn"
output:
    html_document:
        code_folding: hide
        df_print: paged
        toc: true
        toc_float: true
        toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,
                      message=FALSE,
                      cache.lazy=FALSE)
```

Last run: `r date()`

This workflow is designed to conduct pseudobulk differential analysis
on splice junctions with and without CEs.

```{r libraries}
# Libraries
library(tidyverse)
library(ggplot2)
library(ggbeeswarm)
library(parallel)
library(BiocParallel)
library(yaml)
library(RColorBrewer)
library(plotly)
library(parallel)
library(rtracklayer)
library(GenomicRanges)
library(GenomicFeatures)
library(zinbwave)
library(scran)

# Additional options
set.seed(2570)
source('../config/helpers.R')

# Specify the number of available cores
n_cores <- future::availableCores()
options(mc.cores=n_cores)
```

```{r config}

# --------------------------------------------------------------------------------
# This chunk specifies input paths and variables in R
# --------------------------------------------------------------------------------

# Path to input matrices
in_rds <- "sc-exploratory/aggr_matrices.rds"

# Path to Snakemake config
snakemake_config <- "../config/config.yaml"

# Paths to yaml config
config_yaml <- read_yaml(snakemake_config)

# Path to output directory
out_dir <- "sc-pseudobulk"

# Path to GTF
gtf_path <- "../../../input/thalamus_excitatory/genes.gtf.gz"

# Create directories if missing
for (p in c(out_dir)) {
    if (! dir.exists(p)) { dir.create(p, recursive=TRUE) }
}

# Specify metadata columns for factors and factor levels
factor_groups <- list(
    general_disease=c('Control', 'FTD', 'AD'),
    renamed_annotation_cell_type_post_outlier_removal=c( 
        'ExNeu1',
        'ExNeu2',
        'SOX14_Pos_InNeu',
        'SOX14_Neg_InNeu',
        'Mixed'),
    study=c('Marsan', 'Biogen', 'Mathys'),
    study_specific_disease_specific=c(
        'Control-Marsan',
        'Control-Biogen',
        'Control-Mathys',
        'FTD-Marsan',
        'FTD-Biogen',
        'AD-Mathys')
)

# Specify HEX color code
color_map <- list(
    general_disease=c(
        # `Control-FTD`="#9999FF",
        # `Control-AD`="#6666FF",
        Control="#6666FF",
        FTD="#669900",
        AD="#FF6600"),
    study=c(
        Marsan="#FF00FF",
        Biogen="#00FFFF",
        Mathys="#BFBFBF"),
    cell_type=c(
        Astrocyte="#ABD158",
        BVC="#74858C",
        CP="#D5C18E",
        ExNeu1="#90C6E2",
        ExNeu2="#547CB2",
        InNeu1="#21409A",
        InNeu2="#262262",
        Lymphocyte="#68151F",
        Microglia="#D24A75",
        OL="#FDB515",
        OPC="#ED7020",
        PVM="#231F20")
)

# Specify column names to subset barcodes
# NOTE: Set to NULL if unnecessary
id_col <- 'SampleID'
subset_col <- 'study_celltype'
sample_col <- 'SampleID_celltype'
celltype_col <- 'renamed_annotation_cell_type_post_outlier_removal'
disease_col <- "general_disease"
study_col <- 'study'

# Specify CE target genes
ce_targets <- config_yaml[['genes']]

# Pseudocount factor
# NOTE: this number is multiplied by the minimum number of non-zero 
#       junction counts when calculating ratios between cryptic and non-cryptic,
#       as well as between cryptic and all junctions
pseudo_p <- 0.1

# Specify the proportion of y-value to be added to the max data point
ylim_factor <- 0.3
```

# Loading input data {.tabset}

The number of splicing junctions was counted based on cellranger-aligned reads mapped to the following
genes:

```{r genes_tested}
print(ce_targets)
```

Raw junction counts were compiled into a junction-by-barcode matrix for differential testing in the
previous analysis, [`sc-exploratory.html`](sc-exploratory.html). This matrix was preprocessed
to aggregate the counts per sample per celltype, along with their associated metadata table.
These preprocessed matrices and metadata are imported from the following location:

```{r infile_info}
print(in_rds)
```

```{r import_adata}

# --------------------------------------------------------------------------------
# This chunk imports input data saved in the previous single-cell 
# exploratory analysis. Manually edit the following code if necessary.
# --------------------------------------------------------------------------------

# Import input RDS file
obj <- readRDS(in_rds)

# Extract raw count matrices for subsets of interest
mat_list <-  map(obj[['bulk']], ~.x[['raw']])

# Extract the entire sampletable (Edit manually if necessary)
sampletable <- obj[['meta']]
sampletable[[sample_col]] <- paste0(
    sampletable[[id_col]],
    "_",
    sampletable[[celltype_col]])
sampletable[[subset_col]] <- paste0(
    sampletable[[study_col]],
    "_",
    sampletable[[celltype_col]]
)

# Ensure to have correct levels for each factor columns
for (f in names(factor_groups)) {
    sampletable[[f]] <- factor(sampletable[[f]], levels=factor_groups[[f]])
    # Break if any of the conversion introduced missing values
    if (any(is.na(sampletable[[f]]))) {
        stop(paste0("NAs introduced to the following column:", f))
    }
}

# Prep a list of metadata tables for each subset
coldata_list <- mclapply(mat_list, function(m) { 
    # Splice the metadata table based on samples in the matrix
    cdata <- sampletable[sampletable[[sample_col]] %in% colnames(m),
                         c(sample_col, subset_col, names(factor_groups))] %>%
        unique()
    # Break if columns of the matrix and rows of the metadata don't match
    if (nrow(cdata) != ncol(m)) {
        stop("Rownames of coldata and colnames of matrix should be the same!")
    }
    # Reorder rows of the subsetted metadata table
    rownames(cdata) <- cdata[[sample_col]]
    cdata <- cdata[colnames(m),]
    return(cdata)
})

```

# Subsets {.tabset}

The subset-wise aggregation was performed as summarized below:

```{r subset_overview, results='asis'}

# --------------------------------------------------------------------------------
# This chunk explores the number of samples and metadata info across the subsets
# --------------------------------------------------------------------------------

# Function to summarize the number of samples (N)
summarize_N <- function(meta_df) {

    # Count the number of samples
    n_df <- meta_df %>%
        group_by_at(vars(subset_col, disease_col)) %>%
        summarize(N=n()) %>%
        spread(disease_col, N)

    # Replace missing values with zero
    n_df[is.na(n_df)] <- 0
    # Add a new column for all N
    n_df[['all_N']] <- rowSums(n_df[, colnames(n_df)[-1]])

    return(n_df)
}

for (name in names(coldata_list)) {

    df <- coldata_list[[name]] %>%
        remove_rownames()
    cat("##", name, "{.tabset}\n\n")
    cat("### N\n\n")
    # Prep the summary table for N
    n_df <- summarize_N(df)

    # Print tables
    print(knitr::kable(n_df))
    cat('\n\n')

    cat("### Full table\n\n")
    subchunkify(paste0(name, "_subset_N_unfiltered"))
    csv_path <- file.path(out_dir,
                          paste0(name, '_unfiltered_sampletable.csv'))
    write.csv(df,
              csv_path,
              row.names=FALSE,
              quote=FALSE)

    link_table(csv_path)
    cat('\n\n')
}
```

# Pre-filtering nonzero samples {.tabset}

Samples with zero junction counts are removed from each subset. The number of samples before
and after filtering is summarized below.


```{r prefilter_samples, results='asis'}

# --------------------------------------------------------------------------------
# This chunk filters nonzero-count samples
# --------------------------------------------------------------------------------

for (name in names(mat_list)) {
    cat("##", name, "{.tabset}\n\n")
    # Remove zero-count samples from the count matrix
    m <- mat_list[[name]]
    nonzero_samples <- colSums(m) > 0
    m <- m[, nonzero_samples]
    mat_list[[name]] <- m
    # Remove zero-count samples from the metadata table
    cdata_old <- coldata_list[[name]]
    cdata_new <- cdata_old[colnames(m),]
    coldata_list[[name]] <- cdata_new
    
    cat("### N\n\n")
    n_df <- summarize_N(cdata_new)
    cat("A total of",
        sum(!nonzero_samples),
        "samples are removed from the current subset.",
        "Refer to the following table for remaining samples:")
    print(knitr::kable(n_df))
    cat("\n\n")

    cat("### Full table\n\n")
    subchunkify(paste0(name, "_subset_N_filtered"))
    csv_path <- file.path(out_dir,
                          paste0(name, '_filtered_sampletable.csv'))
    write.csv(df,
              csv_path,
              row.names=FALSE,
              quote=FALSE)

    link_table(csv_path)
    cat('\n\n')
}

```

```{r setup_obj}

# --------------------------------------------------------------------------------
# This chunk creates dds objects per subset by modeling zero counts with zinbwave
# (https://github.com/mikelove/zinbwave-deseq2/blob/master/zinbwave-deseq2.Rmd)
# --------------------------------------------------------------------------------

# Convert the count matrix into the SummarizedExperiment obj across the subsets
# NOTE: Features that were undetected in any of the samples are removed here.
#       This is required by zinbwave
se_list <- map(mat_list, ~.x[rowSums(.x) > 0,]) %>% 
    map2(coldata_list,
         ~SummarizedExperiment(assays=list(counts=.x), colData=.y))

# Specify a design formula
design_formula <- as.formula(paste("~", disease_col))

# Run log2(raw_counts + 1) transformation
l2t_list <- lapply(names(se_list), function(name) {
    se <- se_list[[name]]
    # varianceStabilizingTransformation(dds, blind=TRUE)
    m_raw <- assay(se, "counts")
    # Specify a pseudocount to the non-zero min count
    pseudo_c <- min(m_raw[m_raw > 0])
    log2(m_raw + pseudo_c)
}) %>%
set_names(names(se_list))
```

# Quality control (QC)

## Sample similarity heatmap {.tabset}

Sample-to-sample similarity in junction profiling is explored using a heatmap of normalized counts 
(log2 scale), with *Euclidean distance* represented by the color scale. Darker blue indicates
less distance (i.e., greater similarity) in splice junction profiling. Note that this analysis 
excluded junctions that were not detected in any of the samples.

```{r qc_heatmap, results='asis', fig.height=8, fig.width=8}

# --------------------------------------------------------------------------------
# This chunk explores sample similarity using heatmap
# --------------------------------------------------------------------------------

for (name in names(l2t_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Prep a matrix
    scmat <- l2t_list[[name]] %>%
        t() %>%
        dist() %>%
        as.matrix()

    # Set color to be displayed
    colors <- colorRampPalette(rev(RColorBrewer::brewer.pal(9, 'Blues')))(255)

    # Prep metadata for heatmap
    h_meta <- coldata_list[[name]]
    h_meta <- h_meta[, c(disease_col, subset_col)]
    h_meta <- h_meta[, colnames(h_meta) != sample_col]

    # Print heatmap
    print(pheatmap::pheatmap(
        scmat,
        scale='none',
        color=colors,
        annotation_col=h_meta,
        annotation_colors=color_map,
        show_rownames=FALSE,
        show_colnames=FALSE,
        cluster_cols=TRUE,
        border_color=NA
    )
    )
    cat('\n\n')
}

```

## PCA {.tabset}

Another way of looking at sample clustering is principal components analysis (PCA). Each axis does
not have units, rather, it represents the dimensions along which the samples vary the most. The amount 
of variance explained by each principal component is indicated in the axes label. Note that this analysis 
excluded junctions that were not detected in any of the samples.

```{r qc_pca, results='asis', fig.width=8}

# --------------------------------------------------------------------------------
# This chunk explores sample similarity using PCA
# --------------------------------------------------------------------------------

for (name in names(l2t_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Prep a matrix
    scmat <- l2t_list[[name]] %>%
        t()

    # Prep metadata
    p_meta <- coldata_list[[name]]

    # Run PCA
    pca <- prcomp(scmat, center=TRUE, scale=FALSE)
    # Calculate variance explained by each PC
    var_exp <- round(pca$sdev^2/sum(pca$sdev^2) * 100, 2)

    # Prep input dataframe for plotting
    df <- pca$x[,1:2] %>%
        as.data.frame() %>%
        rownames_to_column(sample_col) %>%
        left_join(p_meta, by=sample_col)
    # Prep titles for axes
    axis_titles <- map_chr(
        1:2,
        ~paste0("PC ", .x, " (", var_exp[.x], "%)")
    )

    # Plot PCA
    condition_cols <- colnames(p_meta)[-1] %>%
        sapply(function(c) length(unique(p_meta[[c]])) > 1)
    condition_cols <- colnames(p_meta)[-1][condition_cols]
    for (c in condition_cols) {
        cat('####', c, '\n\n')
        p <- ggplot(df,
                    aes_string(x='PC1',
                               y='PC2',
                               color=c,
                               shape=disease_col)) +
            geom_point(alpha=0.7, size=3) +
            theme_bw() +
            xlab(axis_titles[1]) +
            ylab(axis_titles[2])
        # Add color code if available
        if (c %in% names(color_map)) {
            p <- p + scale_color_manual(values=color_map[[c]])
        }
        print(p)
        cat('\n\n')
    }
}

```

# Distribution of junction counts {.tabset}

Log-normalized pseudobulk counts are compared across disease conditions. Junctions 
with zero counts across all samples are excluded. 

The distribution is shown using a violin plot alongside a scatter plot, where each point 
represents a sample and is colored by study. The black horizontal line indicates the
median of each distribution.

```{r prep_counting}

# --------------------------------------------------------------------------------
# This chunk preps input data frames for plotting
# --------------------------------------------------------------------------------

norm_list <- mclapply(names(mat_list), function(name) {

    # Extract the raw count matrix corresponding to the current subset
    m <- mat_list[[name]]

    # Transform the matrix to a natural log scale and clean data frame
    df <- log1p(m) %>%
        as.data.frame() %>%
        rownames_to_column('junction') %>%
        pivot_longer(!junction,
                     names_to=sample_col,
                     values_to="counts") %>%
        inner_join(sampletable[, c(sample_col, names(factor_groups))],
                   by=sample_col) %>%
        unique() %>%
        as.data.frame()

    # Add a column for spliced gene names
    df[['gene_spliced']] <- map_chr(df[['junction']],
                                    ~str_split(.x, "\\:")[[1]][4])

    # Add a column for generated exons
    df[['exon_detection']] <- ifelse(str_detect(df[['junction']], "non-cryptic"),
                                     "junction detected without CE",
                                     "CE detected")

    return(df)

}) %>%
set_names(names(mat_list))

# Ensure no missing values were introduced
for (name in names(norm_list)) {
    if (any(is.na(norm_list[[name]]))) {
        stop(paste0("Missing values introduced to the following contrast in `norm_list`:",
                    name))
    }
}
```

```{r define_plot_functions}

# --------------------------------------------------------------------------------
# This chunk sets up functions to visualize the distribution of junction counts and ratios
# --------------------------------------------------------------------------------

# Specify the plot format displaying counts
count_plot <- function(input_df, dcol, scol, ylabel) {

    ggplot(input_df,
        aes_string(x=dcol, y='counts', fill=dcol)) +
        geom_violin(trim=TRUE) +
        theme_bw() +
        geom_quasirandom(data=input_df,
                         aes_string(x=dcol, y='counts', color=scol), width=0.2) +
        stat_summary(fun="median",
             geom="crossbar",
             width=0.1,
             color="black") +
        ylab('Log-normalized Junction Counts') +
        theme(axis.title.x=element_blank(),
        axis.text.x=element_text(angle=90, vjust=0.5, hjust=1)) +
        scale_fill_manual(values=color_map[[dcol]]) +
        scale_color_manual(values=color_map[[scol]])
}

# Specify the plot format displaying ratios
ratio_plot <- function(input_df, dcol, scol, ylabel) {

    p <- ggplot(input_df, aes_string(x=dcol, y='ratio', fill=dcol)) +
        geom_violin(trim=TRUE) +
        geom_quasirandom(data=input_df,
                         aes_string(x=dcol, y='ratio', color=scol), width=0.2) +
           stat_summary(fun="median",
                        geom="crossbar",
                        width=0.1,
                        color="black") +
           theme_bw() +
           ylab(ylabel) +
           theme(axis.title.x=element_blank(),
                 axis.text.x=element_text(angle=90, vjust=0.5, hjust=1)) +
           scale_fill_manual(values=color_map[[dcol]]) +
           scale_color_manual(values=color_map[[scol]])

    return(p)
    }

# Function to extract min and max values for ratio
set_min_max <- function(input_list) {

    # Extract all ratios
    vec <- ratio_list %>%
        map(~.x %>%
            bind_rows() %>%
            pull(ratio)) %>%
            unlist()

    # Specify the max ratio value
    c(min=min(vec), max=max(vec))
}

# Function to clean input label
clean_label <- function(input_label) {
    ifelse(str_detect(input_label, "\\:"),
           str_replace(input_label, "\\:", "_"), input_label
    )
}

```

## Counts of splice junctions {.tabset}

Log-normalized pseudobulk counts are compared across the disease conditions. Junctions 
with zero counts across all samples are excluded.

```{r junction_count_dist, results='asis', fig.width=10, fig.height=12}

# --------------------------------------------------------------------------------
# This chunk displays individual junction counts across all disease conditions
# --------------------------------------------------------------------------------

condition_reorder <- c('AD', 'Control', 'FTD')

for (name in names(norm_list)) {
    cat('\n\n###', name, '{.tabset}\n\n')
    df <- norm_list[[name]]
    for (ce in ce_targets) {
        cat('\n\n####', ce, '\n\n')
        # Subset rows for the corresponding CE target gene
        ce_df <- df[str_detect(df$junction, ce), ]
        ce_df[[disease_col]] <- factor(ce_df[[disease_col]],
                                       levels=condition_reorder)

        if (nrow(ce_df) > 0) {

            # Set min and max values for the y-axis
            min_y <- min(ce_df[['counts']])
            max_y <- max(ce_df[['counts']])
            # Plot count distribution
            p <- count_plot(input_df=ce_df,
                            dcol=disease_col,
                            scol=study_col,
                            ylabel='Log-normalized Junction Counts') +
                facet_wrap(. ~ junction, ncol=2) +
                ylim(min_y, max_y + max_y * 0.2)

            plot_name <- paste0(name,
                                "_",
                                ce,
                                "_",
                                sample(1:10000, 1, replace=FALSE))
            h <- ifelse(ce == 'UNC13A', 12, 6)
            w <- 10
            subchunkify(plot_name,
                        input="plot",
                        width=w,
                        height=h,
                        ggplotly=FALSE)

            # Save and link the plot
            lab <- clean_label(name)
            p_path <- file.path(
                out_dir,
                paste0(lab, '_', ce, '_individual_junctions.pdf'))
            ggsave(p_path, p, device="pdf", width=w, height=h)
            link_plot(p_path)
        } else {
            cat("\n\nCount not displayed!\n\n")
        }
    }
}
```

## Counts for CEs {.tabset}

Log-normalized counts are aggregated on whether it results in CE generation.


```{r ce_count_dist, results='asis'}

# --------------------------------------------------------------------------------
# This chunk displays CE or non-CE junction counts across all disease conditions
# --------------------------------------------------------------------------------

for (name in names(norm_list)) {
    cat('\n\n###', name, '{.tabset}\n\n')
    df <- norm_list[[name]]

    for (ce in ce_targets) {
        cat('\n\n####', ce, '\n\n')
        # Subset rows for the corresponding CE target gene
        ce_df <- df[str_detect(df$junction, ce), ] %>%
            group_by_at(vars(sample_col,
                             "exon_detection",
                             disease_col,
                             study_col)) %>%
            summarize(counts=sum(counts))
        ce_df[[disease_col]] <- factor(ce_df[[disease_col]],
                                       levels=condition_reorder)

        if (nrow(ce_df) > 0) {
            # Set min and max values for the y-axis
            min_y <- min(ce_df[['counts']])
            max_y <- max(ce_df[['counts']])
            # Plot count distribution
            p <- count_plot(input_df=ce_df,
                            dcol=disease_col,
                            scol=study_col,
                            ylabel='Log-normalized Counts for Junctions with or without CEs') +
                facet_wrap(. ~ exon_detection) +
                ylim(min_y, max_y + max_y * 0.2)

            print(p)
            # Save and link the plot
            lab <- clean_label(name)
            p_path <- file.path(
                out_dir,
                paste0(lab, '_', ce, '_junction_categories.pdf'))
            ggsave(p_path, p, device="pdf")
            link_plot(p_path)
        } else {
            cat("\n\nCount not displayed!\n\n")
        }
    }
}

```

## CE/non-CE ratios {.tabset}

The counts for junctions with CEs are divided by the counts for junctions without CEs. Note that samples 
not containing any junctions are omitted. 1/10 of non-zero minimum value is added to all remaining entries 
to avoid errors when dividing values. The non-zero minimum value was calculated for each CE target 
(e.g. STMN2) within a subset (e.g. ExNeu1).

```{r ce_ratio}

# --------------------------------------------------------------------------------
# This chunk compares CE/non-CE counts across all disease conditions
# --------------------------------------------------------------------------------

ratio_list <- list()

for (name in names(mat_list)) {
    # Extract input data frame
    df <- norm_list[[name]]
    ratio_list[[name]] <- list()
    for (ce in ce_targets) {
        # Subset rows for the corresponding CE target gene
        ce_df <- df[str_detect(df$junction, ce), ] %>%
            group_by_at(vars(sample_col,
                             "exon_detection",
                             study_col,
                             disease_col)) %>%
            summarize(counts=sum(counts))
        ce_df[[disease_col]] <- factor(ce_df[[disease_col]],
                                       levels=condition_reorder)

        e_detection <- unique(ce_df$exon_detection)
        if (length(e_detection) > 1 & sum(ce_df$counts) > 0) {
            # Calculate the nonzero min value
            nonzero_min <- min(ce_df$counts[ce_df$counts > 0])

            # Prep input for a boxplot
            ce_df <- ce_df %>%
                pivot_wider(names_from=exon_detection, values_from=counts) %>%
                # Impute missing values with zero
                mutate_if(is.numeric, function(x) ifelse(is.na(x), 0, x))

            # Remove samples if they have zero counts for all exon_detection groups
            ce_df <- ce_df[rowSums(ce_df[, e_detection]) > 0,] %>%
                # Add a pseudocount of nonzero_min to all numeric entries
                mutate_if(is.numeric, function(x) x + pseudo_p * nonzero_min) %>%
                # Calculate CE/non-CE counts
                mutate(ratio=`CE detected` / `junction detected without CE`,
                       metric="Ratio") %>%
                as.data.frame() %>%
                unique()

            ratio_list[[name]][[ce]] <- ce_df

        }
    }
}

```

```{r ce_ratio_plot,  results='asis', fig.width=6}

# Extract y-min and y-max from the dataset
min_max_y <- set_min_max(input_list=ratio_list)
min_y <- min_max_y['min']
max_y <- min_max_y['max']

for (name in names(ratio_list)) {
    # Extract input data frame
    cat('\n\n###', name, '{.tabset}\n\n')
    for (ce in names(ratio_list[[name]])) {
        ce_df <- ratio_list[[name]][[ce]]
        if (!is.null(ce_df)) {
            cat('\n\n####', ce, '\n\n')
            # Plot
            p <- ratio_plot(input_df=ce_df,
                            dcol=disease_col,
                            scol=study_col,
                            ylabel='Count Ratios (CE / Non-CE)') + 
                ylim(min_y, max_y)

            print(p)

            # Clean the subset label
            lab <- clean_label(name)
            # Save and link
            p_path <- file.path(
                out_dir,
                paste0(lab, '_', ce, '_ce_over_nonce.pdf'))
            ggsave(p_path, p, device="pdf")
            link_plot(p_path)
            cat('\n\n')
        }
    }
}


```

## CE/all-junctions ratios {.tabset}

The counts for junctions with CEs are divided by the counts for all extracted junctions. Note that samples 
not containing any junctions are omitted. 1/10 of non-zero minimum value is added to all remaining entries 
to avoid errors when dividing values. The non-zero minimum value was calculated for each CE target 
(e.g. STMN2) within a subset (e.g. ExNeu1).

```{r ce_over_all}

# --------------------------------------------------------------------------------
# This chunk compares CE/all counts
# --------------------------------------------------------------------------------

ratio_list <- list()
for (name in names(mat_list)) {
    # Extract input data frame
    df <- norm_list[[name]]
    ratio_list[[name]] <- list()
    for (ce in ce_targets) {
        # Subset rows for the corresponding CE target gene
        ce_df <- df[str_detect(df$junction, ce), ] %>%
            group_by_at(vars(sample_col,
                             "exon_detection",
                             study_col,
                             disease_col)) %>%
            summarize(counts=sum(counts))
        ce_df[[disease_col]] <- factor(ce_df[[disease_col]],
                                       levels=condition_reorder)

        e_detection <- unique(ce_df$exon_detection)
        if (length(e_detection) > 1 & sum(ce_df$counts) > 0) {
            # Calculate the nonzero min value
            nonzero_min <- min(ce_df$counts[ce_df$counts > 0])

            # Prep input for a boxplot
            ce_df <- ce_df %>%
                pivot_wider(names_from=exon_detection, values_from=counts) %>%
                # Impute missing values with zero
                mutate_if(is.numeric, function(x) ifelse(is.na(x), 0, x)) %>%
                as.data.frame()
            # Add a column for all counts
            ce_df[["all junctions"]] <- rowSums(ce_df[, e_detection])

            # Remove samples if they have zero counts for all exon_detection groups
            ce_df <- ce_df[ce_df[['all junctions']] > 0,] %>%
                # Add a pseudocount of nonzero_min to all numeric entries
                mutate_if(is.numeric, function(x) x + pseudo_p * nonzero_min) %>%
                # Calculate CE/non-CE counts
                mutate(ratio=`CE detected` / `all junctions`,
                       metric="Ratio") %>%
                as.data.frame() %>%
                unique()

            ratio_list[[name]][[ce]] <- ce_df
        }
    }
}

```

```{r ce_over_all_plot, results='asis', fig.width=6}

# Extract y-min and y-max from the dataset
min_max_y <- set_min_max(input_list=ratio_list)
min_y <- min_max_y['min']
max_y <- min_max_y['max']

for (name in names(ratio_list)) {
    # Extract input data frame
    cat('\n\n###', name, '{.tabset}\n\n')
    for (ce in names(ratio_list[[name]])) {
    ce_df <- ratio_list[[name]][[ce]]

    if (!is.null(ce_df)) {
        cat('\n\n####', ce, '\n\n')
        # Plot
        p <- ratio_plot(input_df=ce_df,
                        dcol=disease_col,
                        scol=study_col,
                        ylabel='Count Ratios (CE / All-junctions)') + 
            ylim(min_y, max_y + max_y * ylim_factor)

        print(p)


        # Save and link
        lab <- clean_label(name)
        p_path <- file.path(
            out_dir,
            paste0(lab, '_ce_over_alljunction.pdf'))
        ggsave(p_path, p, device="pdf")
        link_plot(p_path)
        cat('\n\n')
        }
    }
}
```

# Pairwise Wilcoxon Rank Sum test {.tabset}

We perform pairwise differential tests comparing each disease group to control. Because the dataset
does not meet the normality assumption, we use a two-tailed Wilcoxon Rank Sum test (Mann-Whitney U),
followed by the BH method. CSV files containing p-values and individual counts are linked below each
result table. Note that contrasts with many zero counts can failed, returning missing values (`NaN`).


```{r prep_stat_test}

# --------------------------------------------------------------------------------
# This chunk sets up a pairwise t- or wilcoxon test
# --------------------------------------------------------------------------------

# Function to calculate p-values using t-test or wilcox test
calc_pval <- function(dataframe, response_col, explanatory_col, split_col, stat="ttest") {

    # Specify a design formula
    formula_str <- paste(response_col, "~", explanatory_col)
    sapply(unique(dataframe[[split_col]]), function(j) {
        df_i <- dataframe[dataframe[[split_col]] == j,]
        tryCatch(
            { 
                if (stat == "ttest") {
                    t.test(as.formula(formula_str), data=df_i)$p.value
                } else if (stat == "wilcox") {
                    wilcox.test(as.formula(formula_str), data=df_i, exact=FALSE)$p.value
                } else {
                    stop("Wrong statistics!")
                }
            },
            error = function(e) { 
                NA 
            })
        }
    )
}

# Function to clean p-values and add FDR
clean_pval <- function(dataframe, dcol, control="Control", padj_method="BH") {
    # Replace p-value with 1 for rows from control group
    dataframe[['pvalue']] <- ifelse(dataframe[[dcol]] == control,
                                    1,
                                    dataframe[['pvalue']])
    # Add a column for FDR
    dataframe[['FDR']] <- p.adjust(dataframe[['pvalue']],
                                   method=padj_method)
    return(dataframe)
}

# Function to subset and clean a count data frame
subset_clean_counts <- function(dataframe, disease_label) {
    dataframe[dataframe[[disease_col]] %in% c('Control', disease_label),] %>%
        group_by_at(vars(sample_col,
                         "exon_detection",
                         "gene_spliced",
                         disease_col)) %>%
        summarize(counts=sum(counts))
}

# Function to run a count division
# denom="nonce" (divide by non-CE junctions) or "all" (divide by all junctions)
calculate_ratios <- function(dataframe, denom="nonce") {

    # Prep input for a boxplot
    dataframe <- dataframe %>%
        pivot_wider(names_from=exon_detection, values_from=counts) %>%
        # Impute missing values with zero
        mutate_if(is.numeric, function(x) ifelse(is.na(x), 0, x))

    # Add a column for all counts
    dataframe[["all junctions"]] <- rowSums(dataframe[, e_detection])

    # Remove samples if they have zero counts for all exon_detection groups
    dataframe <- dataframe[rowSums(dataframe[, e_detection]) > 0,] %>%
        # Add a pseudocount of nonzero_min to all numeric entries
        mutate_if(is.numeric, function(x) x + pseudo_p * nonzero_min) %>%
        as.data.frame() %>%
        unique()

    # Add a new column calculating division
    denom_col <- ifelse(denom == "nonce",
                        "junction detected without CE",
                        "all junctions")
    dataframe[['ratio']] <- dataframe[["CE detected"]] / dataframe[[denom_col]]
    # Add a new column as a placeholder in case not needing to split the data frame
    dataframe[['metric']] <- 'Ratio'

    return(dataframe)
}


# Extract disease labels to be tested in the current dataset
diseases <- factor_groups[[disease_col]]
diseases <- diseases[diseases != "Control"]
```


## Counts for splice junctions {.tabset}

```{r wilcox_junction_counts, results='asis'}

# --------------------------------------------------------------------------------
# This chunk performs a t- or wilcoxon test at on individual junction counts
# --------------------------------------------------------------------------------

for (name in names(norm_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Retrieve input
    df <- norm_list[[name]]
    for (d in diseases) {
        contr_label <- paste0(d, "_vs_Control")
        cat('####', contr_label, '\n\n')
        if (d %in% df[[disease_col]]) {
            # Subset the input data frame 
            df_subset <- df[df[[disease_col]] %in% c('Control', d),]
            # Calculate p-values
            pval <- calc_pval(dataframe=df_subset,
                              response_col='counts',
                              explanatory_col=disease_col,
                              stat='wilcox',
                              split_col='junction')
            # Add FDR
            pval_df <- data.frame(junction=names(pval),
                                  pvalue=pval) %>%
                remove_rownames()

            # Display mean and median counts for each junction
            stat_df <- split(df_subset, df_subset$junction) %>%
                map_df(function(df_i) df_i %>%
                       group_by_at(vars(disease_col, 'junction')) %>%
                       summarize(junction=junction,
                                 N=n(),
                                 average_counts=mean(counts),
                                 median_counts=median(counts)) %>%
                       unique()) %>%
                as.data.frame()

            # Merge statistics, N, and counts
            res_df <- inner_join(stat_df, pval_df, by='junction') %>%
                clean_pval(dcol=disease_col)

            print(knitr::kable(res_df))
            cat('\n\n')

            # Save the stat table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_junction_counts.csv")
            write.csv(res_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)

        } else {
            cat("\n\nContrast unavailable!\n\n")
        }
    }
}

```

## Counts for CEs {.tabset}

```{r wilcox_ce_counts, results='asis'}

# --------------------------------------------------------------------------------
# This chunk performs a t- or wilcoxon test on junction counts associated with CEs or non-CEs
# --------------------------------------------------------------------------------

for (name in names(norm_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Retrieve input
    df <- norm_list[[name]]
    for (d in diseases) {
        contr_label <- paste0(d, "_vs_Control")
        cat('####', contr_label, '\n\n')
        if (d %in% df[[disease_col]]) {
            # Subset the input data frame 
            df_subset <- subset_clean_counts(dataframe=df, disease_label=d)

            # Calculate p-values
            pval_list <- split(df_subset, df_subset[['gene_spliced']])
            pval_df <- map(names(pval_list), function(g) {
                vec <- calc_pval(dataframe=pval_list[[g]],
                    response_col='counts',
                    explanatory_col=disease_col,
                    stat='wilcox',
                    split_col='exon_detection')
                data.frame(gene=g, junction=names(vec), pvalue=vec) }) %>%
                bind_rows() %>%
                remove_rownames()

            # Display mean and median counts for each junction
            stat_list <- split(df_subset, df_subset[['gene_spliced']])
            stat_df <- map(names(stat_list), ~stat_list[[.x]] %>%
                group_by_at(vars(disease_col, 'exon_detection')) %>%
                summarize(gene=.x,
                          N=n(),
                          average_counts=mean(counts),
                          median_counts=median(counts)) %>%
                unique()) %>%
                bind_rows()

            # Merge two data frames
            res_df <- inner_join(pval_df,
                                 stat_df,
                                 by=c('gene', 'junction'='exon_detection')) %>%
                clean_pval(dcol=disease_col)
            # Clean column order
            res_df <- res_df[, c(disease_col,
                                 'gene',
                                 'junction',
                                 'N',
                                 'average_counts',
                                 'median_counts',
                                 'pvalue', 'FDR')]
            print(knitr::kable(res_df))
            cat('\n\n')
            # Save the stat table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_CE_counts.csv")
            write.csv(res_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)

        } else {
            cat("\n\nContrast unavailable!\n\n")
        }
    }
}

```


## CE/non-CE ratios {.tabset}

```{r wilcox_ratios_ce_nonce, results='asis'}

# --------------------------------------------------------------------------------
# This chunk performs a t- or wilcoxon test on count ratios between CE and non-CEs
# --------------------------------------------------------------------------------

for (name in names(norm_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Retrieve input
    df <- norm_list[[name]]
    for (d in diseases) {
        contr_label <- paste0(d, "_vs_Control")
        cat('####', contr_label, '\n\n')
        if (d %in% df[[disease_col]]) {
            # Subset the input data frame 
            df_subset <- subset_clean_counts(dataframe=df, disease_label=d)

            # Calculate p-values
            ratio_list <- split(df_subset, df_subset[['gene_spliced']])
            pval_list <- list()
            df_list <- list()
            for (gene in names(ratio_list)) {
                gene_df <- ratio_list[[gene]]
                e_detection <- unique(gene_df[['exon_detection']])
                if (length(e_detection) > 1 & sum(gene_df$counts) > 0) {
                    # Calculate the nonzero min value
                    nonzero_min <- min(gene_df$counts[gene_df$counts > 0])

                    # Add a division
                    gene_df <- calculate_ratios(dataframe=gene_df, denom="nonce")

                    pval_list[[gene]] <- calc_pval(dataframe=gene_df,
                                                   response_col="ratio",
                                                   explanatory_col=disease_col,
                                                   split_col="metric",
                                                   stat='wilcox') 
                    df_list[[gene]] <- gene_df
                }
            }
            pval_df <- data.frame(gene=names(pval_list),
                                  pvalue=unlist(pval_list)) %>%
                remove_rownames()

            # Display mean and median counts for each junction
            res_df <- df_list %>%
                bind_rows() %>%
                mutate(gene=gene_spliced) %>%
                group_by_at(vars('gene', disease_col)) %>%
                summarize(N=n(),
                          average_ratio=mean(ratio),
                          median_ratio=median(ratio)) %>%
                unique() %>%
                inner_join(pval_df, by='gene') %>%
                clean_pval(dcol=disease_col)

            # Reorder columns
            res_df <- res_df[, c(disease_col,
                                 'gene',
                                 'N',
                                 'average_ratio',
                                 'median_ratio',
                                 'pvalue',
                                 'FDR')]
            print(knitr::kable(res_df))
            cat('\n\n')

            # Save the stat table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_CE_over_nonCE_ratios.csv")
            write.csv(res_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)

        } else {
            cat("\n\nContrast unavailable!\n\n")
        }
    }
}

```

## CE/all-junctions ratios {.tabset}

```{r wilcox_ratios_ce_all, results='asis'}

# --------------------------------------------------------------------------------
# This chunk performs a t- or wilcoxon test on count ratios between CE and all junctions
# --------------------------------------------------------------------------------

for (name in names(norm_list)) {
    cat('###', name, '{.tabset}\n\n')
    # Retrieve input
    df <- norm_list[[name]]
    for (d in diseases) {
        contr_label <- paste0(d, "_vs_Control")
        cat('####', contr_label, '\n\n')
        if (d %in% df[[disease_col]]) {
            # Subset the input data frame 
            df_subset <- subset_clean_counts(dataframe=df, disease_label=d)

            # Calculate p-values
            ratio_list <- split(df_subset, df_subset[['gene_spliced']])
            pval_list <- list()
            df_list <- list()
            for (gene in names(ratio_list)) {
                gene_df <- ratio_list[[gene]]
                e_detection <- unique(gene_df[['exon_detection']])
                if (length(e_detection) > 1 & sum(gene_df$counts) > 0) {
                    # Calculate the nonzero min value
                    nonzero_min <- min(gene_df$counts[gene_df$counts > 0])

                    # Add a division
                    gene_df <- calculate_ratios(dataframe=gene_df, denom="all")

                    pval_list[[gene]] <- calc_pval(dataframe=gene_df,
                                                   response_col="ratio",
                                                   explanatory_col=disease_col,
                                                   split_col="metric",
                                                   stat='wilcox') 
                    df_list[[gene]] <- gene_df
                }
            }
            pval_df <- data.frame(gene=names(pval_list),
                                  pvalue=unlist(pval_list)) %>%
                remove_rownames()

            # Display mean and median counts for each junction
            res_df <- df_list %>%
                bind_rows() %>%
                mutate(gene=gene_spliced) %>%
                group_by_at(vars('gene', disease_col)) %>%
                summarize(N=n(),
                          average_ratio=mean(ratio),
                          median_ratio=median(ratio)) %>%
                unique() %>%
                inner_join(pval_df, by='gene') %>%
                clean_pval(dcol=disease_col)

            # Reorder columns
            res_df <- res_df[, c(disease_col,
                                 'gene',
                                 'N',
                                 'average_ratio',
                                 'median_ratio',
                                 'pvalue',
                                 'FDR')]

            print(knitr::kable(res_df))
            cat('\n\n')

            # Save the stat table as a csv file
            csv_path <- paste0(out_dir, "/",
                               name,
                               "_",
                               contr_label,
                               "_CE_over_all_ratios.csv")
            write.csv(res_df,
                      csv_path,
                      row.names=FALSE,
                      quote=FALSE)
            link_table(csv_path)

        } else {
            cat("\n\nContrast unavailable!\n\n")
        }
    }
}

```

# BED files {.tabset}

## Splice junctions

The following BED file contains the splice junctions tested in the current differential analysis.
Refer to the naming convention when loading the file in IGV: `<chr>:<start>:<end>:<gene_name>:<exon_type>`. 

```{r create_intron_bed, results='asis'}

# --------------------------------------------------------------------------------
# This chunk preps a BED file for tested splice junctions
# --------------------------------------------------------------------------------

# Prep coordinates and annotation in a data frame
df <- data.frame(junction=rownames(se_list[[1]])) %>%
    separate(junction,
             c('chr', 'start', 'end', 'gene_name', 'exon_type'),
             sep=":") %>%
    unite("annotation", chr:exon_type, remove=FALSE, sep=":") %>%
    dplyr::select(chr, start, end, annotation)

# Save
bed_path <- file.path(out_dir, "junctions.bed")
write.table(df,
            file=bed_path,
            sep="\t",
            col.names=FALSE,
            row.names=FALSE,
            quote=FALSE)

link_table(bed_path)
```
 


# Session info

```{r session_info, collapse=FALSE}
sessionInfo()
```

